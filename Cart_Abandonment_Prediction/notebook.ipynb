{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6bf467f",
   "metadata": {
    "papermill": {
     "duration": 0.087849,
     "end_time": "2022-01-27T10:32:41.781835",
     "exception": false,
     "start_time": "2022-01-27T10:32:41.693986",
     "status": "completed"
    },
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "<a id=\"introduction\"></a>\n",
    "# Introduction\n",
    "\n",
    "The biggest challenge eCommerce businesses face these days is how to reduce cart abandonment rates. In fact, the average cart abandonment rate across industries is really high. \n",
    "\n",
    "The marketing team would like to lower these number by identifying these users and giving them incentives so they finalize their carts.\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "    - [Retrieving the data](#retrieving-the-data)\n",
    "    - [Objective](#objective)   \n",
    "* [1. User behavior](#user-behavior)\n",
    "    - [Behavior according to events](#behavior-according-to-events)\n",
    "    - [Event statistics](#event-statistics)\n",
    "    - [Average session duration](#event-statistics)\n",
    "    - [User statistics](#user-statistics)\n",
    "    - [Product statistics](#product-statistics)\n",
    "    - [Conclusion](#conclusion-1)\n",
    "* [2. Boosting model](#boosting-model)\n",
    "    - [Transforming the data](#transforming-the-data)\n",
    "    - [Product information](#product-information)\n",
    "    - [Session information](#session-information)    \n",
    "    - [Feature engineering](#feature-engineering)\n",
    "    - [Modeling with LightGBM](#modeling-with-lightlbm)\n",
    "    - [Model evaluation](#model-evaluation)    \n",
    "    - [Conclusion](#conclusion-2)\n",
    "* [3. Optimization of hyperparameters](#optimization-of-hyperparameters)    \n",
    "    - [Calibration curve](#calibration-curve)    \n",
    "    - [Conclusion](#conclusion-3)    \n",
    "* [4. Validation and interpretability](#optimization-of-hyperparameters)    \n",
    "    - [Validate the model](#validate-the-model)\n",
    "    - [Class densities](#class-densities)        \n",
    "    - [ROC curve](#roc-curve)    \n",
    "    - [Precision-recall curve](#precision-recall-curve)    \n",
    "    - [Shapley values](#shapley-values)        \n",
    "    - [SHAP](#SHAP)\n",
    "    - [Conclusion](#conclusion-3)        \n",
    "* [Conclusion](#conclusion)    \n",
    "\n",
    "<a id=\"retrieving-the-data\"></a>\n",
    "## Retrieving the data\n",
    "\n",
    "The dataset we are going to manipulate contains user events on an E-Commerce platform. For this, we have nearly 7 months of records where, for each event (product visited, added to cart, purchase, ...), we have the following information.\n",
    "\n",
    "- __event_time__ : the event timestamp (UTC format).\n",
    "- __event_type__: the type of event.\n",
    "- __product_id__ : a unique identifier associated to the product.\n",
    "- __category_id__: a unique identifier associated with the product category.\n",
    "- __category_code__: a code associated with the product category.\n",
    "- __brand__: the brand of the product.\n",
    "- __price__: the price of the product.\n",
    "- __user_id__: a unique identifier associated with the user.\n",
    "- __user_session__: a temporary identifier for a user session in UUID format, created when the user arrives and kept until the user leaves the site.\n",
    "\n",
    "The entire dataset totals nearly 50 GB of files. To do this, we will first study a sample.\n",
    "\n",
    "For this project on Kaggle only 150 Mb will be used.\n",
    "\n",
    "<a id=\"objective\"></a>\n",
    "## Objective\n",
    "\n",
    "The objective for this project is to optimize targeted offers for marketing operations by proposing discounts for users during their shopping journey. \\\n",
    "To do this, __we are interested in knowing whether, during a session, a user will buy a product or not__, based on his or her known path so far.\n",
    "\n",
    "We need to know more about the information we have at our disposal in order to build variables that will provide the maximum information to our predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a20c0",
   "metadata": {
    "papermill": {
     "duration": 0.084375,
     "end_time": "2022-01-27T10:32:41.950272",
     "exception": false,
     "start_time": "2022-01-27T10:32:41.865897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"user-behavior\"></a>\n",
    "# 1. User Behavior\n",
    "\n",
    "In this first chapter, we will try to understand a little bit better the behavior of users.\n",
    "\n",
    "\n",
    "<a id=\"#behavior-according-to-events\"></a>\n",
    "\n",
    "## Behavior according to events\n",
    "\n",
    "In this part, we're going to look at whether there is a difference in behavior between views and purchases based on time. Let's start by loading the sample we have and converting some columns into specific types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7dc255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:32:42.133227Z",
     "iopub.status.busy": "2022-01-27T10:32:42.132492Z",
     "iopub.status.idle": "2022-01-27T10:32:47.825365Z",
     "shell.execute_reply": "2022-01-27T10:32:47.824661Z",
     "shell.execute_reply.started": "2022-01-27T09:37:21.161248Z"
    },
    "papermill": {
     "duration": 5.788802,
     "end_time": "2022-01-27T10:32:47.825550",
     "exception": false,
     "start_time": "2022-01-27T10:32:42.036748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.units as munits\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "# Allows to display the x-axis more attractively\n",
    "converter = mdates.ConciseDateConverter()\n",
    "munits.registry[np.datetime64] = converter\n",
    "munits.registry[datetime.date] = converter\n",
    "munits.registry[datetime.datetime] = converter\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('../input/ecommerce-user-actions/sample.csv')\n",
    "\n",
    "# Convert event_time to datetime format\n",
    "data[\"event_time\"] = pd.to_datetime(data[\"event_time\"])\n",
    "\n",
    "data[\"event_day\"] = data[\"event_time\"].dt.day\n",
    "data[\"event_hour\"] = data[\"event_time\"].dt.hour\n",
    "data[\"event_minute\"] = data[\"event_time\"].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841c539",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:32:48.010150Z",
     "iopub.status.busy": "2022-01-27T10:32:48.009334Z",
     "iopub.status.idle": "2022-01-27T10:32:48.031174Z",
     "shell.execute_reply": "2022-01-27T10:32:48.032341Z",
     "shell.execute_reply.started": "2022-01-27T09:37:27.360540Z"
    },
    "papermill": {
     "duration": 0.121989,
     "end_time": "2022-01-27T10:32:48.032605",
     "exception": false,
     "start_time": "2022-01-27T10:32:47.910616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Sample size:\", data.shape[0])\n",
    "print(\"Memory size: {:2.2f} Mb\".format(data.memory_usage().sum() / 1e6))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec454d5",
   "metadata": {
    "papermill": {
     "duration": 0.088293,
     "end_time": "2022-01-27T10:32:48.207523",
     "exception": false,
     "start_time": "2022-01-27T10:32:48.119230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This sample of raw data contains 1.24 million rows. Let's take a closer look at what information is present in this raw data. \n",
    "\n",
    "As mentioned before, we find the mentioned columns.\n",
    "\n",
    "- First of all, two columns indicate the temporality and the type of event: it is the case of the **event_time** columns, indicating the date and the time when the event took place in UTC format (ISO 8601 standard), and **event_type** for the type of event.\n",
    "- Then, some variables concern the user, notably **user_id** and **user_session**.\n",
    "- Finally, the other information is related to the product concerned by the event: these are the **product_id**, **category_id**, **category_code**, **brand** and **price** columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a161942",
   "metadata": {
    "papermill": {
     "duration": 0.086653,
     "end_time": "2022-01-27T10:32:48.380644",
     "exception": false,
     "start_time": "2022-01-27T10:32:48.293991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"event-statistics\"></a>\n",
    "## Event statistics\n",
    "Let's study each variable, independently of the others with **univariate analyses**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c6cde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:32:48.559002Z",
     "iopub.status.busy": "2022-01-27T10:32:48.558225Z",
     "iopub.status.idle": "2022-01-27T10:32:55.997966Z",
     "shell.execute_reply": "2022-01-27T10:32:55.997357Z",
     "shell.execute_reply.started": "2022-01-27T09:37:27.393290Z"
    },
    "papermill": {
     "duration": 7.531877,
     "end_time": "2022-01-27T10:32:55.998127",
     "exception": false,
     "start_time": "2022-01-27T10:32:48.466250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Date min: {}\".format(data[\"event_time\"].min()))\n",
    "print(\"Date max: {}\".format(data[\"event_time\"].max()))\n",
    "\n",
    "plt.figure(figsize=(14, 9))\n",
    "sns.histplot(data[\"event_time\"])\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Number of events\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18be898",
   "metadata": {
    "papermill": {
     "duration": 0.089207,
     "end_time": "2022-01-27T10:32:56.175645",
     "exception": false,
     "start_time": "2022-01-27T10:32:56.086438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we can see the sample contains data from on one day only.\n",
    "\n",
    "The traffic peaks between 16h and 18h before it drop drastically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2f9dc",
   "metadata": {
    "papermill": {
     "duration": 0.085535,
     "end_time": "2022-01-27T10:32:56.347669",
     "exception": false,
     "start_time": "2022-01-27T10:32:56.262134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let's check the different type of events that have been registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f91e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:32:56.526653Z",
     "iopub.status.busy": "2022-01-27T10:32:56.525989Z",
     "iopub.status.idle": "2022-01-27T10:32:56.616703Z",
     "shell.execute_reply": "2022-01-27T10:32:56.617221Z",
     "shell.execute_reply.started": "2022-01-27T09:37:32.450554Z"
    },
    "papermill": {
     "duration": 0.183151,
     "end_time": "2022-01-27T10:32:56.617409",
     "exception": false,
     "start_time": "2022-01-27T10:32:56.434258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data[\"event_type\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32923194",
   "metadata": {
    "papermill": {
     "duration": 0.088548,
     "end_time": "2022-01-27T10:32:56.792588",
     "exception": false,
     "start_time": "2022-01-27T10:32:56.704040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The event type are described below:\n",
    "\n",
    "- **view** - a user has viewed a product page\n",
    "- **cart** - a user has added a product in the basket\n",
    "- **purchase** - a user has purchased a product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd89fe24",
   "metadata": {
    "papermill": {
     "duration": 0.086244,
     "end_time": "2022-01-27T10:32:56.966564",
     "exception": false,
     "start_time": "2022-01-27T10:32:56.880320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Normally there are lot more 'views' than 'purhcases'.\n",
    "\n",
    "The graphs below shows the distribution between the 3 event types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aeff05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:32:57.157692Z",
     "iopub.status.busy": "2022-01-27T10:32:57.156908Z",
     "iopub.status.idle": "2022-01-27T10:32:57.548396Z",
     "shell.execute_reply": "2022-01-27T10:32:57.549319Z",
     "shell.execute_reply.started": "2022-01-27T09:37:32.553435Z"
    },
    "papermill": {
     "duration": 0.490152,
     "end_time": "2022-01-27T10:32:57.549512",
     "exception": false,
     "start_time": "2022-01-27T10:32:57.059360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "events_type_counts = data[\"event_type\"].value_counts() / data.shape[0]\n",
    "print(events_type_counts)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8), subplot_kw=dict(aspect=\"equal\"))\n",
    "\n",
    "wedges, texts = ax.pie(\n",
    "    events_type_counts,\n",
    "    wedgeprops=dict(width=0.4)\n",
    ")\n",
    "\n",
    "# Display text associated with wedges\n",
    "for i, p in enumerate(wedges):\n",
    "    ang = (p.theta2 - p.theta1)/2. + p.theta1\n",
    "    y = np.sin(np.deg2rad(ang))\n",
    "    x = np.cos(np.deg2rad(ang))\n",
    "    horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
    "    ax.annotate(\n",
    "        \"{} : {:2.2f}%\".format(events_type_counts.index[i], events_type_counts[i] * 100),\n",
    "        xy=(x, y), xytext=(1.1*np.sign(x), 1.4*y),\n",
    "        fontsize=16,\n",
    "        horizontalalignment=horizontalalignment)\n",
    "\n",
    "ax.set_title(\"Proportion of event types in the sample\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1979c47",
   "metadata": {
    "papermill": {
     "duration": 0.08773,
     "end_time": "2022-01-27T10:32:57.726795",
     "exception": false,
     "start_time": "2022-01-27T10:32:57.639065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Of course, as this is an E-Commerce site, we expect to have an *over-representation* of **view** events compared to **purchase** events.\n",
    "\n",
    "This graphs is important in case we decide to use a binary classification that will calculate the probability of the finalisation of the purchase. It shows that the data is __imbalanced__, which means one of the classes is over represented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f95bdf",
   "metadata": {
    "papermill": {
     "duration": 0.08976,
     "end_time": "2022-01-27T10:32:57.904675",
     "exception": false,
     "start_time": "2022-01-27T10:32:57.814915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### View vs. purchase\n",
    "\n",
    "To compare the two distributions of events and purchases, histograms are a powerful visualization tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f379be2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:32:58.089990Z",
     "iopub.status.busy": "2022-01-27T10:32:58.089011Z",
     "iopub.status.idle": "2022-01-27T10:33:06.170913Z",
     "shell.execute_reply": "2022-01-27T10:33:06.170283Z",
     "shell.execute_reply.started": "2022-01-27T09:37:32.957214Z"
    },
    "papermill": {
     "duration": 8.176921,
     "end_time": "2022-01-27T10:33:06.171071",
     "exception": false,
     "start_time": "2022-01-27T10:32:57.994150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.histplot(\n",
    "    data.loc[data[\"event_type\"] == \"view\", \"event_time\"],\n",
    "    bins=150\n",
    ")\n",
    "plt.ylabel(\"Views\")\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.histplot(\n",
    "    data.loc[data[\"event_type\"] == \"purchase\", \"event_time\"],\n",
    "    bins=150\n",
    ")\n",
    "plt.ylabel(\"Purchases\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a26d0",
   "metadata": {
    "papermill": {
     "duration": 0.090134,
     "end_time": "2022-01-27T10:33:06.351045",
     "exception": false,
     "start_time": "2022-01-27T10:33:06.260911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"average-session-duration\"></a>\n",
    "## Average session duration\n",
    "Now we are interested in knowing the average session length.\n",
    "\n",
    "_Info:_ Sessions with only one page view will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3716dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:06.539781Z",
     "iopub.status.busy": "2022-01-27T10:33:06.539133Z",
     "iopub.status.idle": "2022-01-27T10:33:07.552001Z",
     "shell.execute_reply": "2022-01-27T10:33:07.551013Z",
     "shell.execute_reply.started": "2022-01-27T09:37:38.476630Z"
    },
    "papermill": {
     "duration": 1.107413,
     "end_time": "2022-01-27T10:33:07.552161",
     "exception": false,
     "start_time": "2022-01-27T10:33:06.444748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sessions_duration = data.groupby(\"user_session\").agg({\"event_time\": [np.min, np.max]}).reset_index()\n",
    "sessions_duration[\"amax\"] = pd.to_datetime(sessions_duration[\"event_time\"][\"amax\"])\n",
    "sessions_duration[\"amin\"] = pd.to_datetime(sessions_duration[\"event_time\"][\"amin\"])\n",
    "sessions_duration.columns = sessions_duration.columns.get_level_values(0)\n",
    "sessions_duration[\"duration\"] = (sessions_duration[\"amax\"] - sessions_duration[\"amin\"])\n",
    "\n",
    "# Remove the sessions with only one page view.\n",
    "sessions_duration = sessions_duration[sessions_duration[\"duration\"].dt.seconds > 0]\n",
    "\n",
    "# Average session duration\n",
    "sessions_duration[\"duration\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc2818f",
   "metadata": {
    "papermill": {
     "duration": 0.090054,
     "end_time": "2022-01-27T10:33:07.733733",
     "exception": false,
     "start_time": "2022-01-27T10:33:07.643679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's visualize the distribution of session durations between 0-60 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee90306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:07.919929Z",
     "iopub.status.busy": "2022-01-27T10:33:07.919244Z",
     "iopub.status.idle": "2022-01-27T10:33:18.470452Z",
     "shell.execute_reply": "2022-01-27T10:33:18.469788Z",
     "shell.execute_reply.started": "2022-01-27T09:37:39.442874Z"
    },
    "papermill": {
     "duration": 10.645827,
     "end_time": "2022-01-27T10:33:18.470606",
     "exception": false,
     "start_time": "2022-01-27T10:33:07.824779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))\n",
    "sns.histplot(sessions_duration[\"duration\"].dt.seconds)\n",
    "plt.title(\"Number of session per duration\", fontsize=17)\n",
    "plt.xlabel(\"Duration (i seconds)\")\n",
    "plt.xlim(0, 3600)  # We display the histogram between 0 and 1h\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9197a6",
   "metadata": {
    "papermill": {
     "duration": 0.093509,
     "end_time": "2022-01-27T10:33:18.658075",
     "exception": false,
     "start_time": "2022-01-27T10:33:18.564566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we would like to know if users whose sessions lasts more than 1 hour buy more often than others.\n",
    "\n",
    "**Procedure**\n",
    "\n",
    "- Separate the users into user groups whose session is less than 1 hour and more than 1 hour.\n",
    "- Calculate the proportion of purchases per user group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5cc250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:18.855920Z",
     "iopub.status.busy": "2022-01-27T10:33:18.855170Z",
     "iopub.status.idle": "2022-01-27T10:33:20.236474Z",
     "shell.execute_reply": "2022-01-27T10:33:20.237031Z",
     "shell.execute_reply.started": "2022-01-27T09:37:50.267822Z"
    },
    "papermill": {
     "duration": 1.485326,
     "end_time": "2022-01-27T10:33:20.237226",
     "exception": false,
     "start_time": "2022-01-27T10:33:18.751900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List long sessions\n",
    "longer_sessions = sessions_duration[sessions_duration[\"duration\"].dt.seconds > 3600][\"user_session\"].values\n",
    "\n",
    "data_purchase = data.copy()\n",
    "data_purchase['purchased'] = np.where(data_purchase['event_type'] == \"purchase\", 1, 0)\n",
    "data_purchase['purchased'] = data_purchase \\\n",
    "    .groupby([\"user_session\"])['purchased'] \\\n",
    "    .transform(\"max\")\n",
    "\n",
    "print(data_purchase['purchased'].sample(5))\n",
    "\n",
    "purchased_over_hour = data_purchase[data_purchase[\"user_session\"].isin(longer_sessions)][\"purchased\"]\n",
    "\n",
    "print(\"Proportion of users making a purchase for session duration > 1h :\",\n",
    "    round((purchased_over_hour.value_counts()[1] / purchased_over_hour.shape[0])*100, 2), \"%\"\n",
    ")\n",
    "\n",
    "print(\"Proportion of users making a purchase for session duration < 1h :\",\n",
    "    round((data_purchase[\"purchased\"].value_counts()[1] /  data_purchase[\"purchased\"].shape[0])*100, 2), \"%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eba704",
   "metadata": {
    "papermill": {
     "duration": 0.092937,
     "end_time": "2022-01-27T10:33:20.423059",
     "exception": false,
     "start_time": "2022-01-27T10:33:20.330122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If we want to move towards a binary classification that will calculate the probability of q user finalizing a purchase, it is very important to know in advance if the dataset will be imbalanced, i.e. that one of the two classes will be overwhelmingly present (99% vs 1%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19eb197",
   "metadata": {
    "papermill": {
     "duration": 0.096165,
     "end_time": "2022-01-27T10:33:20.613908",
     "exception": false,
     "start_time": "2022-01-27T10:33:20.517743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#user-statistics\"></a>\n",
    "## User statistics\n",
    "\n",
    "There are two important user identifiers in the dataset.\n",
    "\n",
    "- The **user_id** column, gives a unique identifier for a user.\n",
    "- The **session_id** column, in UUID format, gives the unique identifier for a user session.\n",
    "\n",
    "<blockquote style='padding:20px'>A UUID is an identifier that uses time to ensure uniqueness (in the sense that it is very likely to have exactly two sessions that start at the same millisecond or even microsecond).</blockquote>\n",
    "\n",
    "The user session is an important concept to master here: when a user visits the site, a session is created. This session is kept throughout the user journey on the site. As soon as the user leaves the platform, after a certain time, the session is stopped.\n",
    "\n",
    "For example, if the user visits the site 3 times in one day, for example 10 minutes in the morning, 5 minutes in the afternoon and 20 minutes in the evening, then three sessions will be created during that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a551f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:20.805615Z",
     "iopub.status.busy": "2022-01-27T10:33:20.804861Z",
     "iopub.status.idle": "2022-01-27T10:33:21.005732Z",
     "shell.execute_reply": "2022-01-27T10:33:21.005087Z",
     "shell.execute_reply.started": "2022-01-27T09:37:51.644496Z"
    },
    "papermill": {
     "duration": 0.29886,
     "end_time": "2022-01-27T10:33:21.005876",
     "exception": false,
     "start_time": "2022-01-27T10:33:20.707016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Unique number of users:\", len(data[\"user_id\"].unique()))\n",
    "print(\"Number of sessions :\", len(data[\"user_session\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ede76",
   "metadata": {
    "papermill": {
     "duration": 0.091419,
     "end_time": "2022-01-27T10:33:21.190929",
     "exception": false,
     "start_time": "2022-01-27T10:33:21.099510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have 268737 sessions for 190188 users: this means that there is a large proportion of users who have only one session.\n",
    "\n",
    "Let's see what proportion of users have only one session in the sample.\n",
    "\n",
    "#### Proportion of users by number of session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7c5ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:21.384922Z",
     "iopub.status.busy": "2022-01-27T10:33:21.383918Z",
     "iopub.status.idle": "2022-01-27T10:33:21.979300Z",
     "shell.execute_reply": "2022-01-27T10:33:21.978757Z",
     "shell.execute_reply.started": "2022-01-27T09:37:51.851539Z"
    },
    "papermill": {
     "duration": 0.696505,
     "end_time": "2022-01-27T10:33:21.979466",
     "exception": false,
     "start_time": "2022-01-27T10:33:21.282961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "\n",
    "num_sessions_per_user = data[[\"user_id\", \"user_session\"]].groupby(\"user_id\").count()[\"user_session\"].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Calculer la proportion\n",
    "num_sessions_per_user /= num_sessions_per_user.sum()\n",
    "\n",
    "plt.figure(figsize=(14,9))\n",
    "n_bars = 12\n",
    "\n",
    "rects = plt.bar(num_sessions_per_user[:n_bars].index, height=num_sessions_per_user[:n_bars])\n",
    "for rect in rects:\n",
    "    height = rect.get_height()\n",
    "    # Ajouter du text à chaque bar\n",
    "    plt.gca().annotate(\n",
    "        # Convertir la proportion en percentage\n",
    "        '{:2.2f}%'.format(height * 100),\n",
    "        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "        xytext=(0, 3),\n",
    "        textcoords=\"offset points\",\n",
    "        fontsize=16 * 10 / n_bars,\n",
    "        ha='center', va='bottom'\n",
    "    )\n",
    "\n",
    "plt.ylabel(\"Proportion of users\")\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.xticks(range(1, n_bars + 1))\n",
    "plt.xlabel(\"Number of sessions\")\n",
    "plt.title(\"Proportion of users by number of sessions\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef4d003",
   "metadata": {
    "papermill": {
     "duration": 0.093132,
     "end_time": "2022-01-27T10:33:22.169856",
     "exception": false,
     "start_time": "2022-01-27T10:33:22.076724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We notice that more than 70% of the users have at least two sessions in the sample: it could therefore be interesting to use this information as an explanatory variable later on.\n",
    "\n",
    "#### How many sessions resulted in a purchase of one of the visited products?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263aa425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:22.364538Z",
     "iopub.status.busy": "2022-01-27T10:33:22.363741Z",
     "iopub.status.idle": "2022-01-27T10:33:23.556842Z",
     "shell.execute_reply": "2022-01-27T10:33:23.556213Z",
     "shell.execute_reply.started": "2022-01-27T09:37:52.451631Z"
    },
    "papermill": {
     "duration": 1.293705,
     "end_time": "2022-01-27T10:33:23.557008",
     "exception": false,
     "start_time": "2022-01-27T10:33:22.263303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_purchase = data.copy()\n",
    "data_purchase['purchased'] = np.where(data_purchase['event_type'] == \"purchase\", 1, 0) # purchased = 1\n",
    "data_purchase['purchased'] = data_purchase.groupby([\"user_session\"])['purchased'].transform(\"max\")\n",
    "\n",
    "print(data_purchase['purchased'].sample(5))\n",
    "\n",
    "data_purchase[\"purchased\"].value_counts() / data_purchase[\"purchased\"].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cda4b7",
   "metadata": {
    "papermill": {
     "duration": 0.095184,
     "end_time": "2022-01-27T10:33:23.751475",
     "exception": false,
     "start_time": "2022-01-27T10:33:23.656291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This means that about 10% of the sessions end with at least one purchase of one of the visited products. This statistic informs us that the data set is not unbalanced between the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d2605c",
   "metadata": {
    "papermill": {
     "duration": 0.099417,
     "end_time": "2022-01-27T10:33:23.950633",
     "exception": false,
     "start_time": "2022-01-27T10:33:23.851216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#product-statistics\"></a>\n",
    "## Product statistics\n",
    "\n",
    "Let's now look at the products. In the **data_categories** DataFrame, we will calculate the number of events (views, adds to cart and purchases) per product category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823cf21e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:24.157166Z",
     "iopub.status.busy": "2022-01-27T10:33:24.156085Z",
     "iopub.status.idle": "2022-01-27T10:33:29.740816Z",
     "shell.execute_reply": "2022-01-27T10:33:29.740283Z",
     "shell.execute_reply.started": "2022-01-27T09:37:53.582847Z"
    },
    "papermill": {
     "duration": 5.69499,
     "end_time": "2022-01-27T10:33:29.740994",
     "exception": false,
     "start_time": "2022-01-27T10:33:24.046004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_categories = data.copy()\n",
    "data_categories[\"category\"] = data_categories[\"category_code\"].str.split(\".\", expand=True)[0]\n",
    "\n",
    "for event_type in [\"view\", \"cart\", \"purchase\"]:\n",
    "    data_categories[\"event_{}\".format(event_type)] = np.where(data_categories[\"event_type\"] == event_type, 1, 0)\n",
    "    \n",
    "data_categories = data_categories[[\"event_view\", \"event_cart\", \"event_purchase\", \"category\"]].groupby(\"category\").sum()\n",
    "data_categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbcf070",
   "metadata": {
    "papermill": {
     "duration": 0.094625,
     "end_time": "2022-01-27T10:33:29.931765",
     "exception": false,
     "start_time": "2022-01-27T10:33:29.837140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To know which categories are the most visited, let's display the values on a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8448240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:30.128624Z",
     "iopub.status.busy": "2022-01-27T10:33:30.127857Z",
     "iopub.status.idle": "2022-01-27T10:33:30.436853Z",
     "shell.execute_reply": "2022-01-27T10:33:30.436209Z",
     "shell.execute_reply.started": "2022-01-27T09:37:59.144443Z"
    },
    "papermill": {
     "duration": 0.408795,
     "end_time": "2022-01-27T10:33:30.437029",
     "exception": false,
     "start_time": "2022-01-27T10:33:30.028234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,9))\n",
    "\n",
    "rects = plt.barh(data_categories.index, width=data_categories[\"event_view\"])\n",
    "for rect in rects:\n",
    "    width = rect.get_width()\n",
    "    plt.gca().annotate(\n",
    "        '{}'.format(int(width)),\n",
    "        xy=(width, rect.get_y()),\n",
    "        xytext=(30, 5),\n",
    "        textcoords=\"offset points\",\n",
    "        fontsize=16 * 10 / n_bars,\n",
    "        ha='center', va='bottom'\n",
    "    )\n",
    "\n",
    "plt.ylabel(\"Category\")\n",
    "plt.xlabel(\"Number of views\")\n",
    "plt.title(\"Number of views by product category\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2851fb",
   "metadata": {
    "papermill": {
     "duration": 0.096356,
     "end_time": "2022-01-27T10:33:30.630430",
     "exception": false,
     "start_time": "2022-01-27T10:33:30.534074",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "What we observe is that the **electronics** category is the most visited one, with more than 450 000 views. On the other hand, others are very little visited like **stationery** or **medicine** with less than 500 views during a whole day.\n",
    "\n",
    "Let's do the same thing for purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a516ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:30.826359Z",
     "iopub.status.busy": "2022-01-27T10:33:30.825678Z",
     "iopub.status.idle": "2022-01-27T10:33:31.134396Z",
     "shell.execute_reply": "2022-01-27T10:33:31.133696Z",
     "shell.execute_reply.started": "2022-01-27T09:37:59.467676Z"
    },
    "papermill": {
     "duration": 0.407545,
     "end_time": "2022-01-27T10:33:31.134542",
     "exception": false,
     "start_time": "2022-01-27T10:33:30.726997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,9))\n",
    "\n",
    "rects = plt.barh(data_categories.index, width=data_categories[\"event_purchase\"])\n",
    "for rect in rects:\n",
    "    width = rect.get_width()\n",
    "    plt.gca().annotate(\n",
    "        '{}'.format(int(width)),\n",
    "        xy=(width, rect.get_y()),\n",
    "        xytext=(30, 5),\n",
    "        textcoords=\"offset points\",\n",
    "        fontsize=16 * 10 / n_bars,\n",
    "        ha='center', va='bottom'\n",
    "    )\n",
    "\n",
    "plt.ylabel(\"Category\")\n",
    "plt.xlabel(\"Number of purchases\")\n",
    "plt.title(\"Number of purchases by product category\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be5b75",
   "metadata": {
    "papermill": {
     "duration": 0.097839,
     "end_time": "2022-01-27T10:33:31.331386",
     "exception": false,
     "start_time": "2022-01-27T10:33:31.233547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Not surprisingly, the categories with the most views are also the ones with the most purchases. But let's take a look at the purchase/view ratios for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4199467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:31.537736Z",
     "iopub.status.busy": "2022-01-27T10:33:31.537043Z",
     "iopub.status.idle": "2022-01-27T10:33:31.843906Z",
     "shell.execute_reply": "2022-01-27T10:33:31.843253Z",
     "shell.execute_reply.started": "2022-01-27T09:37:59.806693Z"
    },
    "papermill": {
     "duration": 0.414962,
     "end_time": "2022-01-27T10:33:31.844070",
     "exception": false,
     "start_time": "2022-01-27T10:33:31.429108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,9))\n",
    "\n",
    "rects = plt.barh(data_categories.index, width=data_categories[\"event_purchase\"] / data_categories[\"event_view\"])\n",
    "for rect in rects:\n",
    "    width = rect.get_width()\n",
    "    plt.gca().annotate(\n",
    "        '{:2.2f}%'.format(width * 100),\n",
    "        xy=(width, rect.get_y()),\n",
    "        xytext=(30, 5),\n",
    "        textcoords=\"offset points\",\n",
    "        fontsize=16 * 10 / n_bars,\n",
    "        ha='center', va='bottom'\n",
    "    )\n",
    "\n",
    "plt.ylabel(\"Category\")\n",
    "plt.xlabel(\"Ratio\")\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=1))\n",
    "plt.title(\"Number of purchases per number of views ratio\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2b4a5",
   "metadata": {
    "papermill": {
     "duration": 0.101419,
     "end_time": "2022-01-27T10:33:32.047443",
     "exception": false,
     "start_time": "2022-01-27T10:33:31.946024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Surprisingly, while there are far fewer visits for **medicine** products than electronics (order x 10000 ), the former records the same proportion of purchases / views as the latter.\n",
    "\n",
    "<a id=\"#conclusion-1\"></a>\n",
    "## Conclusion\n",
    "From now on, we have a clearer idea about the data we are manipulating.\n",
    "\n",
    "- User behavior cannot be reduced to a single event.\n",
    "- Interactions between variables seem to be high.\n",
    "\n",
    "From this knowledge, we will be able to implement a first algorithm with __LightGBM__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78e7cfd",
   "metadata": {
    "papermill": {
     "duration": 0.100297,
     "end_time": "2022-01-27T10:33:32.248500",
     "exception": false,
     "start_time": "2022-01-27T10:33:32.148203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#boosting-model\"></a>\n",
    "# 2. Boosting model\n",
    "\n",
    "Now that we have more knowledge about the data, we can start by transforming the data and training a first model. Our choice is __LightGBM__, because of its training speed of and its performance that is close to XGBoost.\n",
    "\n",
    "<a id=\"#transforming-the-data\"></a>\n",
    "## Transforming the data\n",
    "\n",
    "Let's go back to the sample we studied before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042f4bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:32.467772Z",
     "iopub.status.busy": "2022-01-27T10:33:32.454478Z",
     "iopub.status.idle": "2022-01-27T10:33:32.471479Z",
     "shell.execute_reply": "2022-01-27T10:33:32.470930Z",
     "shell.execute_reply.started": "2022-01-27T09:38:00.129215Z"
    },
    "papermill": {
     "duration": 0.121452,
     "end_time": "2022-01-27T10:33:32.471626",
     "exception": false,
     "start_time": "2022-01-27T10:33:32.350174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5aa53",
   "metadata": {
    "papermill": {
     "duration": 0.100558,
     "end_time": "2022-01-27T10:33:32.672659",
     "exception": false,
     "start_time": "2022-01-27T10:33:32.572101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As mentioned previously, we want to know if a user will buy a product during a session or not. Thus, our learning base will be made up of sessions where we know whether the user has bought this product or not.\n",
    "\n",
    "Each observation of our learning base will have the following information.\n",
    "\n",
    "- Information related to the product (number of views of the product in the session, category, product ID).\n",
    "- Session information (duration in seconds, number of previous sessions, start time).\n",
    "\n",
    "We will therefore transform the sample to obtain this information.\n",
    "\n",
    "<a id=\"#product-information\"></a>\n",
    "## Product Information\n",
    "\n",
    "According to our goal, our learning base will represent a set of sessions where, for each session and each product, the user has purchased (column \"purchased\" = 1) this product or not (column \"purchased\" = 0). We will therefore have to **aggregate the rows** having the same user session and for the same product.\n",
    "\n",
    "Let's start by building the **purchased** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5817fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:32.878994Z",
     "iopub.status.busy": "2022-01-27T10:33:32.878279Z",
     "iopub.status.idle": "2022-01-27T10:33:34.798697Z",
     "shell.execute_reply": "2022-01-27T10:33:34.798052Z",
     "shell.execute_reply.started": "2022-01-27T09:38:00.150310Z"
    },
    "papermill": {
     "duration": 2.025152,
     "end_time": "2022-01-27T10:33:34.798835",
     "exception": false,
     "start_time": "2022-01-27T10:33:32.773683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We get the events whose user_session column is not null\n",
    "# ~data[\"user_session\"].isna() -> does not contain isna()\n",
    "# The copy() method returns a new list, it does not modify the original list. If the original list is modified, events_per_session will not be modified.\n",
    "# This would be the case if \"=\" is used -> events_per_session = data.loc[~data[\"user_session\"].isna(), :]\n",
    "events_per_session = data.loc[~data[\"user_session\"].isna(), :].copy()\n",
    "\n",
    "# We create a purchase column which is 0 or 1, depending on the event_type column\n",
    "events_per_session['purchased'] = np.where(events_per_session['event_type'] == \"purchase\", 1, 0)\n",
    "\n",
    "# We aggregate by session and by product to know if the latter has been purchased in the session\n",
    "events_per_session['purchased'] = events_per_session \\\n",
    "    .groupby([\"user_session\", \"product_id\"])['purchased'] \\\n",
    "    .transform(\"max\")\n",
    "\n",
    "events_per_session.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722b7f1",
   "metadata": {
    "papermill": {
     "duration": 0.100378,
     "end_time": "2022-01-27T10:33:35.000201",
     "exception": false,
     "start_time": "2022-01-27T10:33:34.899823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If the purchased column is 1, it means that during the session, the user has purchased the product.\n",
    "\n",
    "Let's do the same thing for the number of views in the session by creating the column **num_views**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908be97d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:35.237171Z",
     "iopub.status.busy": "2022-01-27T10:33:35.235625Z",
     "iopub.status.idle": "2022-01-27T10:33:38.002225Z",
     "shell.execute_reply": "2022-01-27T10:33:38.002750Z",
     "shell.execute_reply.started": "2022-01-27T09:38:02.111545Z"
    },
    "papermill": {
     "duration": 2.901043,
     "end_time": "2022-01-27T10:33:38.002934",
     "exception": false,
     "start_time": "2022-01-27T10:33:35.101891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We determine how many times the user has seen products in the session\n",
    "events_per_session['num_views_session'] = np.where(events_per_session['event_type'] == \"view\", 1, 0)\n",
    "events_per_session['num_views_session'] = events_per_session.groupby([\"user_session\"]) \\\n",
    "    ['num_views_session'].transform(\"sum\")\n",
    "\n",
    "# Determines how many times the user has seen a particular product in the session\n",
    "events_per_session['num_views_product'] = np.where(events_per_session['event_type'] == \"view\", 1, 0)\n",
    "events_per_session['num_views_product'] = events_per_session.groupby([\"user_session\", \"product_id\"]) \\\n",
    "    ['num_views_product'].transform(\"sum\")\n",
    "\n",
    "events_per_session.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3519d9d",
   "metadata": {
    "papermill": {
     "duration": 0.107755,
     "end_time": "2022-01-27T10:33:38.216276",
     "exception": false,
     "start_time": "2022-01-27T10:33:38.108521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will also perform a **split** on the **category_code** column to retrieve the category and sub-category of each product (if they exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06ae42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:38.429144Z",
     "iopub.status.busy": "2022-01-27T10:33:38.428143Z",
     "iopub.status.idle": "2022-01-27T10:33:45.950595Z",
     "shell.execute_reply": "2022-01-27T10:33:45.949692Z",
     "shell.execute_reply.started": "2022-01-27T09:38:04.813481Z"
    },
    "papermill": {
     "duration": 7.62827,
     "end_time": "2022-01-27T10:33:45.950749",
     "exception": false,
     "start_time": "2022-01-27T10:33:38.322479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "events_per_session['category'] = events_per_session['category_code'].str.split(\".\",expand=True)[0].astype('category')\n",
    "events_per_session['sub_category'] = events_per_session['category_code'].str.split(\".\",expand=True)[1].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a46b443",
   "metadata": {
    "papermill": {
     "duration": 0.111797,
     "end_time": "2022-01-27T10:33:46.166719",
     "exception": false,
     "start_time": "2022-01-27T10:33:46.054922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we convert the **event_time** column into a **datetime** object, which allows us to retrieve precisely the hour, minute and day of the week associated with the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86743138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:46.395521Z",
     "iopub.status.busy": "2022-01-27T10:33:46.394474Z",
     "iopub.status.idle": "2022-01-27T10:33:46.813161Z",
     "shell.execute_reply": "2022-01-27T10:33:46.813766Z",
     "shell.execute_reply.started": "2022-01-27T09:38:12.390710Z"
    },
    "papermill": {
     "duration": 0.527207,
     "end_time": "2022-01-27T10:33:46.813981",
     "exception": false,
     "start_time": "2022-01-27T10:33:46.286774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "events_per_session[\"event_time\"] = pd.to_datetime(events_per_session[\"event_time\"], utc=True)\n",
    "\n",
    "events_per_session[\"hour\"] = events_per_session[\"event_time\"].dt.hour\n",
    "events_per_session[\"minute\"] = events_per_session[\"event_time\"].dt.minute\n",
    "events_per_session[\"weekday\"] = events_per_session[\"event_time\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eab2cb",
   "metadata": {
    "papermill": {
     "duration": 0.102183,
     "end_time": "2022-01-27T10:33:47.018414",
     "exception": false,
     "start_time": "2022-01-27T10:33:46.916231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#session-information\"></a>   \n",
    "## Session information\n",
    "\n",
    "Now let's look at the sessions of each user. We'll start by determining the durations of each session. The easiest way to do this is to group the observations by **user_session**, then calculate the minimum and maximum of the **event_time** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e773ba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:47.227119Z",
     "iopub.status.busy": "2022-01-27T10:33:47.226090Z",
     "iopub.status.idle": "2022-01-27T10:33:48.220883Z",
     "shell.execute_reply": "2022-01-27T10:33:48.220267Z",
     "shell.execute_reply.started": "2022-01-27T09:38:12.816935Z"
    },
    "papermill": {
     "duration": 1.101147,
     "end_time": "2022-01-27T10:33:48.221043",
     "exception": false,
     "start_time": "2022-01-27T10:33:47.119896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We calculate the minimum and maximum date of each session\n",
    "sessions_duration = events_per_session \\\n",
    "    .groupby(\"user_session\").agg(\n",
    "        {\"event_time\": [np.min, np.max]}\n",
    "    ).reset_index()\n",
    "\n",
    "sessions_duration[\"amax\"] = pd.to_datetime(sessions_duration[\"event_time\"][\"amax\"])\n",
    "sessions_duration[\"amin\"] = pd.to_datetime(sessions_duration[\"event_time\"][\"amin\"])\n",
    "del sessions_duration[\"event_time\"]\n",
    "\n",
    "# The columns are flattened to level 0\n",
    "sessions_duration.columns = sessions_duration.columns.get_level_values(0)\n",
    "\n",
    "# We calculate the total duration, in seconds, of each TimeDelta\n",
    "sessions_duration[\"duration\"] = (sessions_duration[\"amax\"] - sessions_duration[\"amin\"]).dt.seconds\n",
    "sessions_duration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3565b247",
   "metadata": {
    "papermill": {
     "duration": 0.106818,
     "end_time": "2022-01-27T10:33:48.430269",
     "exception": false,
     "start_time": "2022-01-27T10:33:48.323451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When duration = 0, only one event has been created, but without a second event that followed during the session.\n",
    "\n",
    "Once calculated, we simply need to do a **join** with the **events_per_session** DataFrame, the result of which will be stored in the **dataset** data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02825f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:48.641851Z",
     "iopub.status.busy": "2022-01-27T10:33:48.640512Z",
     "iopub.status.idle": "2022-01-27T10:33:49.970761Z",
     "shell.execute_reply": "2022-01-27T10:33:49.971344Z",
     "shell.execute_reply.started": "2022-01-27T09:38:13.782961Z"
    },
    "papermill": {
     "duration": 1.437928,
     "end_time": "2022-01-27T10:33:49.971560",
     "exception": false,
     "start_time": "2022-01-27T10:33:48.533632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = events_per_session \\\n",
    "    .sort_values(\"event_time\") \\\n",
    "    .drop_duplicates([\"event_type\", \"product_id\", \"user_id\", \"user_session\"]) \\\n",
    "    .loc[events_per_session[\"event_type\"].isin([\"cart\", \"purchase\"])] \\\n",
    "    .merge(\n",
    "        sessions_duration[[\"user_session\", \"duration\"]],\n",
    "        how=\"left\",\n",
    "        on=\"user_session\"\n",
    "    )\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba3651",
   "metadata": {
    "papermill": {
     "duration": 0.104054,
     "end_time": "2022-01-27T10:33:50.181041",
     "exception": false,
     "start_time": "2022-01-27T10:33:50.076987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that here we use a **drop_duplicates** to remove duplicate rows: they correspond to the same product, event type, user, and session (for example, a user who visits the same product twice in a single session).\n",
    "\n",
    "<blockquote style='padding:20px'>We already harvested this information above by calculating the number of views per session.</blockquote>\n",
    "\n",
    "Another question that may prove interesting: has the user had other sessions before? For this, it is important to establish **an order relationship**, especially with **event_time**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b672a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:50.393479Z",
     "iopub.status.busy": "2022-01-27T10:33:50.392749Z",
     "iopub.status.idle": "2022-01-27T10:33:50.485171Z",
     "shell.execute_reply": "2022-01-27T10:33:50.484586Z",
     "shell.execute_reply.started": "2022-01-27T09:38:15.276614Z"
    },
    "papermill": {
     "duration": 0.202012,
     "end_time": "2022-01-27T10:33:50.485337",
     "exception": false,
     "start_time": "2022-01-27T10:33:50.283325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_prev_sessions = dataset[[\"user_id\", \"user_session\", \"event_time\"]] \\\n",
    "    .sort_values(\"event_time\") \\\n",
    "    .groupby([\"user_id\", \"user_session\"]) \\\n",
    "    .first() \\\n",
    "    .reset_index()\n",
    "\n",
    "# cumcount() allows to do a cumulative count of the lines: 0, 1, 2, 3, ...\n",
    "count_prev_sessions[\"num_prev_sessions\"] = count_prev_sessions \\\n",
    "    .sort_values(\"event_time\") \\\n",
    "    .groupby(\"user_id\") \\\n",
    "    .cumcount()\n",
    "\n",
    "count_prev_sessions.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21942874",
   "metadata": {
    "papermill": {
     "duration": 0.103271,
     "end_time": "2022-01-27T10:33:50.694335",
     "exception": false,
     "start_time": "2022-01-27T10:33:50.591064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As always, we perform a join with dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c5c03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:50.921298Z",
     "iopub.status.busy": "2022-01-27T10:33:50.910760Z",
     "iopub.status.idle": "2022-01-27T10:33:50.943274Z",
     "shell.execute_reply": "2022-01-27T10:33:50.942712Z",
     "shell.execute_reply.started": "2022-01-27T09:38:15.381615Z"
    },
    "papermill": {
     "duration": 0.144449,
     "end_time": "2022-01-27T10:33:50.943430",
     "exception": false,
     "start_time": "2022-01-27T10:33:50.798981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.merge(\n",
    "    count_prev_sessions[[\"user_session\", \"num_prev_sessions\"]],\n",
    "    how=\"left\",\n",
    "    on=\"user_session\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637e5154",
   "metadata": {
    "papermill": {
     "duration": 0.104732,
     "end_time": "2022-01-27T10:33:51.151822",
     "exception": false,
     "start_time": "2022-01-27T10:33:51.047090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "One last piece of information that might also be useful is whether the user has already seen a particular product in a previous session. It is very similar to the previous transformation, except that the **product_id** and **user_id** must also be taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d4a97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:51.368825Z",
     "iopub.status.busy": "2022-01-27T10:33:51.367615Z",
     "iopub.status.idle": "2022-01-27T10:33:51.496569Z",
     "shell.execute_reply": "2022-01-27T10:33:51.495908Z",
     "shell.execute_reply.started": "2022-01-27T09:38:15.426282Z"
    },
    "papermill": {
     "duration": 0.240389,
     "end_time": "2022-01-27T10:33:51.496716",
     "exception": false,
     "start_time": "2022-01-27T10:33:51.256327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "view_prev_session = dataset[[\"user_id\", \"user_session\", \"event_time\", \"product_id\"]]\n",
    "view_prev_session = view_prev_session \\\n",
    "    .sort_values(\"event_time\") \\\n",
    "    .groupby([\"user_id\", \"user_session\", \"product_id\"]) \\\n",
    "    .first() \\\n",
    "    .reset_index()\n",
    "\n",
    "# cumcount() permits to do a cumulative counter of the rows: 1, 2, 3...\n",
    "view_prev_session[\"num_prev_product_views\"] = view_prev_session \\\n",
    "    .sort_values(\"event_time\") \\\n",
    "    .groupby([\"user_id\", \"product_id\"]) \\\n",
    "    .cumcount()\n",
    "\n",
    "dataset = dataset.merge(\n",
    "    view_prev_session[[\"user_session\", \"product_id\", \"num_prev_product_views\"]],\n",
    "    how=\"left\",\n",
    "    on=[\"user_session\", \"product_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab27be7",
   "metadata": {
    "papermill": {
     "duration": 0.104622,
     "end_time": "2022-01-27T10:33:51.707051",
     "exception": false,
     "start_time": "2022-01-27T10:33:51.602429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we will remove duplicate rows from the **user_session**, **product_id** and **purchased** columns, if for example a user has purchased the same product more than once (in which case the outcome would always be the positive class from the moment the product is purchased at least once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c52765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:51.924169Z",
     "iopub.status.busy": "2022-01-27T10:33:51.923437Z",
     "iopub.status.idle": "2022-01-27T10:33:52.178913Z",
     "shell.execute_reply": "2022-01-27T10:33:52.178350Z",
     "shell.execute_reply.started": "2022-01-27T09:38:15.551389Z"
    },
    "papermill": {
     "duration": 0.367524,
     "end_time": "2022-01-27T10:33:52.179082",
     "exception": false,
     "start_time": "2022-01-27T10:33:51.811558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset \\\n",
    "    .sort_values(\"event_time\") \\\n",
    "    .drop_duplicates([\"user_session\", \"product_id\", \"purchased\"]) \\\n",
    "    .drop([\"event_time\", \"event_type\", \"category_code\", \"category_id\"], axis=1)\n",
    "\n",
    "dataset.to_csv(\"dataset.csv\", index=False)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d85ecc",
   "metadata": {
    "papermill": {
     "duration": 0.105028,
     "end_time": "2022-01-27T10:33:52.389099",
     "exception": false,
     "start_time": "2022-01-27T10:33:52.284071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can now check the proportion of the two classes present in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec48733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:52.607829Z",
     "iopub.status.busy": "2022-01-27T10:33:52.607162Z",
     "iopub.status.idle": "2022-01-27T10:33:52.614534Z",
     "shell.execute_reply": "2022-01-27T10:33:52.613627Z",
     "shell.execute_reply.started": "2022-01-27T09:38:15.828249Z"
    },
    "papermill": {
     "duration": 0.119008,
     "end_time": "2022-01-27T10:33:52.614734",
     "exception": false,
     "start_time": "2022-01-27T10:33:52.495726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Dataset size:\", dataset.shape[0])\n",
    "proportions = round(dataset[\"purchased\"].value_counts() / dataset.shape[0] * 100, 2)\n",
    "print(\"Proportions in %\\n{}\".format(proportions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b4cd8c",
   "metadata": {
    "papermill": {
     "duration": 0.104918,
     "end_time": "2022-01-27T10:33:52.826970",
     "exception": false,
     "start_time": "2022-01-27T10:33:52.722052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our dataset **is not unbalanced**, so there is no resampling to apply.\n",
    "\n",
    "Let's save the data to a CSV file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7293469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:53.047921Z",
     "iopub.status.busy": "2022-01-27T10:33:53.043523Z",
     "iopub.status.idle": "2022-01-27T10:33:53.249974Z",
     "shell.execute_reply": "2022-01-27T10:33:53.249224Z",
     "shell.execute_reply.started": "2022-01-27T09:38:15.840026Z"
    },
    "papermill": {
     "duration": 0.319462,
     "end_time": "2022-01-27T10:33:53.250130",
     "exception": false,
     "start_time": "2022-01-27T10:33:52.930668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.to_csv(\"primary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be5006",
   "metadata": {
    "papermill": {
     "duration": 0.105179,
     "end_time": "2022-01-27T10:33:53.459825",
     "exception": false,
     "start_time": "2022-01-27T10:33:53.354646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#feature-engineer\"></a>\n",
    "## Feature engineering\n",
    "\n",
    "Now that our data frame **dataset** contains the observations, we have to apply a **feature engineering** step to make the learning base numerically transformed and usable by our model. \n",
    "\n",
    "There are really only three columns to encode: brand, category and sub_category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0452e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:53.680460Z",
     "iopub.status.busy": "2022-01-27T10:33:53.679630Z",
     "iopub.status.idle": "2022-01-27T10:33:53.865886Z",
     "shell.execute_reply": "2022-01-27T10:33:53.865251Z",
     "shell.execute_reply.started": "2022-01-27T09:38:16.082415Z"
    },
    "papermill": {
     "duration": 0.301078,
     "end_time": "2022-01-27T10:33:53.866052",
     "exception": false,
     "start_time": "2022-01-27T10:33:53.564974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# The features are the learning base that are encoded numerically\n",
    "features = dataset.drop([\"user_id\", \"user_session\"], axis=1).copy()\n",
    "\n",
    "for label in [\"category\", \"sub_category\", \"brand\"]:\n",
    "    features[label] = features[label].astype(str)\n",
    "    features.loc[features[label] == 'nan', label] = \"unknown\"\n",
    "    features.loc[:, label] = LabelEncoder().fit_transform(features.loc[:, label].copy())\n",
    "\n",
    "features['weekday'] = features['weekday'].astype(int)\n",
    "features.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49451d8a",
   "metadata": {
    "papermill": {
     "duration": 0.10706,
     "end_time": "2022-01-27T10:33:54.080058",
     "exception": false,
     "start_time": "2022-01-27T10:33:53.972998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can now see that all the columns are now numerical.\n",
    "\n",
    "Let's check that there are no missing values, because that can create problems with boosting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfabb3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:54.295714Z",
     "iopub.status.busy": "2022-01-27T10:33:54.294988Z",
     "iopub.status.idle": "2022-01-27T10:33:54.302577Z",
     "shell.execute_reply": "2022-01-27T10:33:54.301818Z",
     "shell.execute_reply.started": "2022-01-27T09:38:16.276842Z"
    },
    "papermill": {
     "duration": 0.118083,
     "end_time": "2022-01-27T10:33:54.302762",
     "exception": false,
     "start_time": "2022-01-27T10:33:54.184679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cf34c2",
   "metadata": {
    "papermill": {
     "duration": 0.104337,
     "end_time": "2022-01-27T10:33:54.514013",
     "exception": false,
     "start_time": "2022-01-27T10:33:54.409676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "From there, we will create the learning base (X, y) consisting of the features and then separate the base into two subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f9416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:54.730752Z",
     "iopub.status.busy": "2022-01-27T10:33:54.729789Z",
     "iopub.status.idle": "2022-01-27T10:33:54.804134Z",
     "shell.execute_reply": "2022-01-27T10:33:54.803607Z",
     "shell.execute_reply.started": "2022-01-27T09:38:16.289654Z"
    },
    "papermill": {
     "duration": 0.183141,
     "end_time": "2022-01-27T10:33:54.804279",
     "exception": false,
     "start_time": "2022-01-27T10:33:54.621138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = features.drop(\"purchased\", axis=1)\n",
    "y = features['purchased']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=40)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1bf9d",
   "metadata": {
    "papermill": {
     "duration": 0.10655,
     "end_time": "2022-01-27T10:33:55.017821",
     "exception": false,
     "start_time": "2022-01-27T10:33:54.911271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will then save the generated data.\n",
    "\n",
    "<blockquote style='padding:20px'>It is important to have consistency on the sets used to train the models and to evaluate them. This is why the data is saved to files.</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61d34a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:55.237604Z",
     "iopub.status.busy": "2022-01-27T10:33:55.236843Z",
     "iopub.status.idle": "2022-01-27T10:33:55.553422Z",
     "shell.execute_reply": "2022-01-27T10:33:55.552823Z",
     "shell.execute_reply.started": "2022-01-27T09:38:16.368395Z"
    },
    "papermill": {
     "duration": 0.42842,
     "end_time": "2022-01-27T10:33:55.553567",
     "exception": false,
     "start_time": "2022-01-27T10:33:55.125147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.to_csv(\"X.csv\", index=False)\n",
    "y.to_csv(\"y.csv\", index=False)\n",
    "\n",
    "X_train.to_csv(\"X_train.csv\", index=False)\n",
    "X_test.to_csv(\"X_test.csv\", index=False)\n",
    "y_train.to_csv(\"y_train.csv\", index=False)\n",
    "y_test.to_csv(\"y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c67870",
   "metadata": {
    "papermill": {
     "duration": 0.107087,
     "end_time": "2022-01-27T10:33:55.767305",
     "exception": false,
     "start_time": "2022-01-27T10:33:55.660218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#modeling-with-lightlbm\"></a>\n",
    "## Modeling with LightGBM\n",
    "\n",
    "The algorithm we will use is **LightGBM** : it has the advantage of being faster than XGBoost while keeping similar performances.\n",
    "\n",
    "<a href=\"#tree-creation\"></a>\n",
    "### Tree creation\n",
    "\n",
    "Although similar, the main difference between LightGBM and XGBoost is the way the trees are built.\n",
    "\n",
    "XGBoost applies a method called **level-wise tree growth**, where each tree is built level by level. Thus, XGBoost grows the first level (depth 1), and then grows the second level (depth 2) once the previous level has been expanded. This is a horizontal approach.\n",
    "\n",
    "LightGBM applies a method called **leaf-wise tree growth**. Unlike the previous method, the pruning is not done according to the depth, but directly according to the leaves. Thus, LightGBM will spread each leaf vertically, without making sure that the relevant depth is fully spread. This can produce, for example, trees that are not balanced (hence the possibility of always adding the **max_depth** hyper-parameter).\n",
    "\n",
    "<blockquote style='padding:20px'>If we didn't do tree pruning, the trees built with XGBoost and LightGBM would be identical.</blockquote>\n",
    "\n",
    "One of the main reasons LightGBM is very often faster than XGBoost is due to the use of the leaf-wise method.\n",
    "\n",
    "The most important hyperparameters for LightGBM are:\n",
    "\n",
    "- **num_leaves** which controls the number of leaves (nodes) in each tree.\n",
    "- **min_child_samples** specifies the number of observations in a leaf. This is an important hyper-parameter to avoid over-learning, especially when the number of leaves is high.\n",
    "- **max_depth** to control the maximum depth of each tree.\n",
    "- **n_estimators** to determine the number of trees to calibrate.\n",
    "- **learning_rate** to specify the learning rate of each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b814199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:55.985530Z",
     "iopub.status.busy": "2022-01-27T10:33:55.984784Z",
     "iopub.status.idle": "2022-01-27T10:33:56.904968Z",
     "shell.execute_reply": "2022-01-27T10:33:56.904369Z",
     "shell.execute_reply.started": "2022-01-27T09:38:16.716729Z"
    },
    "papermill": {
     "duration": 1.032431,
     "end_time": "2022-01-27T10:33:56.905117",
     "exception": false,
     "start_time": "2022-01-27T10:33:55.872686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6d9b0",
   "metadata": {
    "papermill": {
     "duration": 0.110632,
     "end_time": "2022-01-27T10:33:57.122809",
     "exception": false,
     "start_time": "2022-01-27T10:33:57.012177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's train a LightGBM classifier with the default settings. We will set up a __Repeated k-Fold__ to calculate scores on multiple instances of the model.\n",
    "\n",
    "<blockquote style='padding:20px'>As a reminder, cross-validation is important here to ensure that the calculated score for a model is consistent.</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44637f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:57.391607Z",
     "iopub.status.busy": "2022-01-27T10:33:57.390880Z",
     "iopub.status.idle": "2022-01-27T10:33:57.393325Z",
     "shell.execute_reply": "2022-01-27T10:33:57.394028Z",
     "shell.execute_reply.started": "2022-01-27T09:38:17.626438Z"
    },
    "papermill": {
     "duration": 0.134119,
     "end_time": "2022-01-27T10:33:57.394229",
     "exception": false,
     "start_time": "2022-01-27T10:33:57.260110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We repeat 3 times a 5-Fold\n",
    "rep_kfold = RepeatedKFold(n_splits=4, n_repeats=3)\n",
    "\n",
    "# The models hyperparameters\n",
    "hyp_params = {\n",
    "    \"num_leaves\": 60,\n",
    "    \"min_child_samples\": 10,\n",
    "    \"max_depth\": 12,\n",
    "    \"n_estimators\": 100,\n",
    "    \"learning_rate\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2a0945",
   "metadata": {
    "papermill": {
     "duration": 0.119865,
     "end_time": "2022-01-27T10:33:57.631701",
     "exception": false,
     "start_time": "2022-01-27T10:33:57.511836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will leave the default settings of the LGBMClassifier object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3adb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:33:57.862492Z",
     "iopub.status.busy": "2022-01-27T10:33:57.861218Z",
     "iopub.status.idle": "2022-01-27T10:34:02.510754Z",
     "shell.execute_reply": "2022-01-27T10:34:02.511386Z",
     "shell.execute_reply.started": "2022-01-27T09:38:17.632353Z"
    },
    "papermill": {
     "duration": 4.767901,
     "end_time": "2022-01-27T10:34:02.511594",
     "exception": false,
     "start_time": "2022-01-27T10:33:57.743693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_train = []\n",
    "scores_test = []\n",
    "n_iter = 1\n",
    "for train_I, test_I in rep_kfold.split(X):\n",
    "    print(\"Iteration {} of k-Fold\".format(n_iter))\n",
    "\n",
    "    # We recover the indexes of the subsamples\n",
    "    X_fold_train = X.iloc[train_I, :]\n",
    "    y_fold_train = y.iloc[train_I]\n",
    "    X_fold_test = X.iloc[test_I, :]\n",
    "    y_fold_test = y.iloc[test_I]\n",
    "    \n",
    "    # We train a LightGBM with the default settings\n",
    "    model = LGBMClassifier(**hyp_params, objective=\"binary\", verbose=-1)\n",
    "    model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "    # We calculate the score of the model on the test\n",
    "    scores_train.append(\n",
    "        f1_score(y_fold_train, model.predict(X_fold_train))\n",
    "    )\n",
    "    scores_test.append(\n",
    "        f1_score(y_fold_test, model.predict(X_fold_test))\n",
    "    )\n",
    "    n_iter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08acdbba",
   "metadata": {
    "papermill": {
     "duration": 0.113083,
     "end_time": "2022-01-27T10:34:02.736584",
     "exception": false,
     "start_time": "2022-01-27T10:34:02.623501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's now look at the scores on the two subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a75f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:34:02.967006Z",
     "iopub.status.busy": "2022-01-27T10:34:02.965874Z",
     "iopub.status.idle": "2022-01-27T10:34:03.143546Z",
     "shell.execute_reply": "2022-01-27T10:34:03.142980Z",
     "shell.execute_reply.started": "2022-01-27T09:38:23.114438Z"
    },
    "papermill": {
     "duration": 0.295408,
     "end_time": "2022-01-27T10:34:03.143697",
     "exception": false,
     "start_time": "2022-01-27T10:34:02.848289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "\n",
    "print(\"Mean Train score: {:2.1f}%\".format(np.mean(scores_train) * 100))\n",
    "print(\"Mean Test score: {:2.1f}%\".format(np.mean(scores_test) * 100))\n",
    "\n",
    "scores = pd.DataFrame.from_dict({\n",
    "    \"Train Set\": scores_train,\n",
    "    \"Test Set\": scores_test\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "sns.boxplot(data=scores, orient=\"h\")\n",
    "plt.title(\"Scores of the k-Fold models\", fontsize=17)\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676b3b3",
   "metadata": {
    "papermill": {
     "duration": 0.111852,
     "end_time": "2022-01-27T10:34:03.367880",
     "exception": false,
     "start_time": "2022-01-27T10:34:03.256028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The mean scores for the for the training and test sets are 92.0% and 87.9% respectively. \n",
    "\n",
    "First, we notice from the graph that the variations in scores are small (a standard deviation of about 0.5% for the test set). \\\n",
    "Second, the difference between the two median scores is about 4%, which shows that there is no apparent overlearning of our models.\n",
    "\n",
    "From these results, we can now calibrate a LightGBM on the pair (X_train, y_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e04c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:34:03.600052Z",
     "iopub.status.busy": "2022-01-27T10:34:03.598987Z",
     "iopub.status.idle": "2022-01-27T10:34:03.897406Z",
     "shell.execute_reply": "2022-01-27T10:34:03.898319Z",
     "shell.execute_reply.started": "2022-01-27T09:38:23.294364Z"
    },
    "papermill": {
     "duration": 0.416519,
     "end_time": "2022-01-27T10:34:03.898535",
     "exception": false,
     "start_time": "2022-01-27T10:34:03.482016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LGBMClassifier(**hyp_params, objective=\"binary\", verbose=-1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fd06ce",
   "metadata": {
    "papermill": {
     "duration": 0.112937,
     "end_time": "2022-01-27T10:34:04.127300",
     "exception": false,
     "start_time": "2022-01-27T10:34:04.014363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's also calculate the scores on the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c30400b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:34:04.357254Z",
     "iopub.status.busy": "2022-01-27T10:34:04.356196Z",
     "iopub.status.idle": "2022-01-27T10:34:04.441314Z",
     "shell.execute_reply": "2022-01-27T10:34:04.442052Z",
     "shell.execute_reply.started": "2022-01-27T09:38:23.672845Z"
    },
    "papermill": {
     "duration": 0.203796,
     "end_time": "2022-01-27T10:34:04.442258",
     "exception": false,
     "start_time": "2022-01-27T10:34:04.238462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Train score: {:2.1f}%\".format(f1_score(y_train, model.predict(X_train)) * 100))\n",
    "print(\"Test score: {:2.1f}%\".format(f1_score(y_test, model.predict(X_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e149f95",
   "metadata": {
    "papermill": {
     "duration": 0.11277,
     "end_time": "2022-01-27T10:34:04.667773",
     "exception": false,
     "start_time": "2022-01-27T10:34:04.555003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As expected, the scores are very similar to those obtained by the k-Fold model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151e4333",
   "metadata": {
    "papermill": {
     "duration": 0.111607,
     "end_time": "2022-01-27T10:34:04.892356",
     "exception": false,
     "start_time": "2022-01-27T10:34:04.780749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#model-evaluation\"></a>   \n",
    "## Model evaluation\n",
    "\n",
    "The evaluation of the model is important, because it will allow us to ensure that the model is sufficiently efficient, while having a predictable behavior.\n",
    "\n",
    "__Scores should not be the only metric to evaluate a Machine Learning model.__\n",
    "\n",
    "In addition to the scores, the model must also satisfy other constraints. Indeed, in our marketing case study, we want to know if a customer will complete a purchase during his journey on the e-commerce platform.\n",
    "\n",
    "The objective here is to **encourage the user to finalize his cart**. \\\n",
    "To do this, one method is to offer customized discounts to increase the probability that the user will complete a purchase. __It is therefore a binary classification problem.__ \n",
    "\n",
    "We can thus make two types of errors:\n",
    "\n",
    "- A **false positive** consists in predicting that the user will buy the product when in reality, he will not finalize the purchase. In this case, offering a discount has little impact, since there is a strong chance that the user will not use it.\n",
    "\n",
    "- A **false negative** consists in predicting that the user will not buy the product when in fact he will not finalize the purchase. In this second case, giving a discount to this user implies a loss of profit, since the user would have bought the product anyway, even without the discount code.\n",
    "\n",
    "Here we see that the false negative has more impact in economic terms than the false positive. Indeed, it is better for a user to buy at a discounted price than not to buy a product. Conversely, it is better not to offer a discount to a user who would buy a product even without a discount code.\n",
    "\n",
    "So our goal is to correctly detect false negatives, since they impact profits, as opposed to false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20480cd4",
   "metadata": {
    "papermill": {
     "duration": 0.113674,
     "end_time": "2022-01-27T10:34:05.121718",
     "exception": false,
     "start_time": "2022-01-27T10:34:05.008044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### How to evaluate whether our model is more likely to produce false positives or false negatives?\n",
    "\n",
    "To do this, we need to understand that in binary classification, the output of the model is not a class (or), but a probability (of being in each of the two classes).\n",
    "\n",
    "Let's look at some statistics based on the confusion matrix:\n",
    "\n",
    "- __Specificity__ represents the probability of predicting a non-purchase among users who did not purchase. TN / FP + TN\n",
    "\n",
    "- __Sensitivity__ (or recall) represents the probability of predicting a purchase among users who have purchased. TP / TP + FN\n",
    "\n",
    "- __Precision__ represents the probability of having users who have purchased among the users whose purchase was predicted. TN / TP + FP\n",
    "\n",
    "The first two measures look at the rates among the theoretical knowledge of the behavior, while the last one looks at the rate among the predictions of the model.\n",
    "\n",
    "We have said that it is important to have as few false negatives as possible: it is therefore the sensitivity (or recall) that should be observed. A low recall means that the share of false negatives is large, while a high recall means that the share of false negatives is close to.\n",
    "\n",
    "Recall, by itself, cannot fully determine whether the model is performing well! A model may very well have very high recall, but very low precision. \\\n",
    "This is why we also use the F1 score, which involves both precision and recall.\n",
    "\n",
    "$ Score_{F1} = 2 \\times \\frac {(Precision \\times Recall)}{(Precision + Recall)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2af4ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:34:05.353394Z",
     "iopub.status.busy": "2022-01-27T10:34:05.352698Z",
     "iopub.status.idle": "2022-01-27T10:34:05.405407Z",
     "shell.execute_reply": "2022-01-27T10:34:05.406031Z",
     "shell.execute_reply.started": "2022-01-27T09:38:23.762631Z"
    },
    "papermill": {
     "duration": 0.172402,
     "end_time": "2022-01-27T10:34:05.406241",
     "exception": false,
     "start_time": "2022-01-27T10:34:05.233839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "print(\"Precision Test : {:2.1f}%\".format(precision_score(y_test, model.predict(X_test)) * 100))\n",
    "print(\"Recall Test : {:2.1f}%\".format(recall_score(y_test, model.predict(X_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d0020b",
   "metadata": {
    "papermill": {
     "duration": 0.112478,
     "end_time": "2022-01-27T10:34:05.633548",
     "exception": false,
     "start_time": "2022-01-27T10:34:05.521070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have a very high recall, which means that there are few false negatives. \n",
    "\n",
    "On the other hand, the precision is not as good: there are more false positives, our model often tends to predict a purchase too much when it should not.\n",
    "\n",
    "### How can we improve the accuracy?\n",
    "\n",
    "The interest now is to determine which are the optimal hyperparameters that will allow us to obtain the best performance. For this, a common practice is **AutoML**, which consists in automating the training of the models.\n",
    "\n",
    "And very often, in trying to determine the best hyperparameters, rather than using a grid search, **Bayesian methods** are used.\n",
    "\n",
    "<a id=\"#conclusion-2\"></a>\n",
    "## Conclusion\n",
    "\n",
    "We have just implemented our first predictive model on our data.\n",
    "\n",
    "- The dataset was transformed to be sent to the predictive model.\n",
    "- With a k-Fold, we trained a LightGBM.\n",
    "- We measured the performance obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079fc1d2",
   "metadata": {
    "papermill": {
     "duration": 0.112183,
     "end_time": "2022-01-27T10:34:05.924451",
     "exception": false,
     "start_time": "2022-01-27T10:34:05.812268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#optimization-of-hyperparameters\"></a>  \n",
    "# 3. Optimization of hyperparameters\n",
    "\n",
    "Bayesian optimization is a method for determining the optimal hyper-parameters of a model using Bayesian statistical tools. Their main interest, unlike grid searches, is to use the information acquired during the optimization to determine the next hyper-parameters to be tested.\n",
    "\n",
    "What we will do:\n",
    "\n",
    "- Discover the Bayesian approach to hyper-parameter optimization\n",
    "- Launch a TPE search on LightGBM\n",
    "- Calibrate a model on the best hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62c9fc",
   "metadata": {
    "papermill": {
     "duration": 0.113638,
     "end_time": "2022-01-27T10:34:06.152768",
     "exception": false,
     "start_time": "2022-01-27T10:34:06.039130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will load the training set $(X,y)$ that will be used during the Bayesian optimization with k-Fold, and the training and test subsets to calibrate the model once the best hyperparameters are obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98380255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:34:06.384773Z",
     "iopub.status.busy": "2022-01-27T10:34:06.383682Z",
     "iopub.status.idle": "2022-01-27T10:34:06.464382Z",
     "shell.execute_reply": "2022-01-27T10:34:06.464971Z",
     "shell.execute_reply.started": "2022-01-27T09:38:23.820159Z"
    },
    "papermill": {
     "duration": 0.199226,
     "end_time": "2022-01-27T10:34:06.465156",
     "exception": false,
     "start_time": "2022-01-27T10:34:06.265930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"X.csv\")\n",
    "y = pd.read_csv(\"y.csv\")\n",
    "\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").values.flatten()\n",
    "y_test = pd.read_csv(\"y_test.csv\").values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7b70e1",
   "metadata": {
    "papermill": {
     "duration": 0.111979,
     "end_time": "2022-01-27T10:34:06.690467",
     "exception": false,
     "start_time": "2022-01-27T10:34:06.578488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's define the search space that will be used by the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2af2cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f84445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:34:06.918045Z",
     "iopub.status.busy": "2022-01-27T10:34:06.917316Z",
     "iopub.status.idle": "2022-01-27T10:34:07.365084Z",
     "shell.execute_reply": "2022-01-27T10:34:07.364467Z",
     "shell.execute_reply.started": "2022-01-27T09:42:28.672267Z"
    },
    "papermill": {
     "duration": 0.562855,
     "end_time": "2022-01-27T10:34:07.365251",
     "exception": false,
     "start_time": "2022-01-27T10:34:06.802396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from hyperopt import hp, tpe, fmin\n",
    "\n",
    "MODEL_SPECS = {\n",
    "    \"name\": \"LightGBM\",\n",
    "    \"class\": LGBMClassifier,\n",
    "    \"max_evals\": 20, # \"max_evals\": 20,\n",
    "    \"params\": {\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.001, 1),\n",
    "        \"num_iterations\": hp.quniform(\"num_iterations\", 100, 1000, 20),\n",
    "        \"max_depth\": hp.quniform(\"max_depth\", 4, 12, 6),\n",
    "        \"num_leaves\": hp.quniform(\"num_leaves\", 8, 128, 10),\n",
    "        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.3, 1),\n",
    "        \"subsample\": hp.uniform(\"subsample\", 0.5, 1),\n",
    "        \"min_child_samples\": hp.quniform(\"min_child_samples\", 1, 20, 10),\n",
    "        \"reg_alpha\": hp.choice(\"reg_alpha\", [0, 1e-1, 1, 2, 5, 10]),\n",
    "        \"reg_lambda\": hp.choice(\"reg_lambda\", [0, 1e-1, 1, 2, 5, 10]),\n",
    "    },\n",
    "    \"override_schemas\": {\n",
    "        \"num_leaves\": int, \"min_child_samples\": int, \"max_depth\": int, \"num_iterations\": int\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b9970b",
   "metadata": {
    "papermill": {
     "duration": 0.112918,
     "end_time": "2022-01-27T10:34:07.594152",
     "exception": false,
     "start_time": "2022-01-27T10:34:07.481234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The list of LightGBM hyperparameters can be found in the documentation of the model.\n",
    "\n",
    "To facilitate the maintenance of the code, we encapsulate the optimisation process in an **optimize_hyp** function which requires several arguments:\n",
    "\n",
    "- __instance__ is the class inherited from BaseEstimator of scikit-learn to instantiate a model.\n",
    "- __training_set__ is the training base $(X,y)$.\n",
    "- __search_space__ is the search space for the optimizer.\n",
    "- __metric__ is the metric to be used to calculate the score.\n",
    "- __evals__ is the number of iterations of the optimizer.\n",
    "\n",
    "<blockquote style='padding:20px'>In <b>hyperopt</b>, we seek to minimise an objective function: we must therefore return the additive inverse in the case where the metric used is a score.</blockquote>\n",
    "\n",
    "In some cases, the hyperparameters of the search space are not always integers (10.0 instead of 10), which can generate errors. The **override_schemas** field contains a list of hyperparameters for which the conversion to integer is explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1871b04f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:34:07.826045Z",
     "iopub.status.busy": "2022-01-27T10:34:07.825303Z",
     "iopub.status.idle": "2022-01-27T10:34:07.834825Z",
     "shell.execute_reply": "2022-01-27T10:34:07.835411Z",
     "shell.execute_reply.started": "2022-01-27T09:42:39.798099Z"
    },
    "papermill": {
     "duration": 0.129013,
     "end_time": "2022-01-27T10:34:07.835594",
     "exception": false,
     "start_time": "2022-01-27T10:34:07.706581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "def optimize_hyp(instance, training_set, search_space, metric, evals=10):\n",
    "    # Function to be minimised (inverse of tau)\n",
    "    def objective(params):\n",
    "        for param in set(list(MODEL_SPECS[\"override_schemas\"].keys())).intersection(set(params.keys())):\n",
    "            cast_instance = MODEL_SPECS['override_schemas'][param]\n",
    "            params[param] = cast_instance(params[param])\n",
    "            \n",
    "        # Repeat 3 times a 5-Fold\n",
    "        rep_kfold = RepeatedKFold(n_splits=4, n_repeats=1)\n",
    "        scores_test = []\n",
    "        for train_I, test_I in rep_kfold.split(X):\n",
    "            X_fold_train = X.iloc[train_I, :]\n",
    "            y_fold_train = y.iloc[train_I]\n",
    "            X_fold_test = X.iloc[test_I, :]\n",
    "            y_fold_test = y.iloc[test_I]\n",
    "\n",
    "            # A LightGBM is trained with the default settings\n",
    "            model = LGBMClassifier(**params, objective=\"binary\", verbose=-1)\n",
    "            model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "            # We calculate the score of the model on the test\n",
    "            scores_test.append(\n",
    "                metric(y_fold_test, model.predict(X_fold_test))\n",
    "            )\n",
    "\n",
    "        return np.mean(scores_test)\n",
    "\n",
    "    return fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c01647",
   "metadata": {
    "papermill": {
     "duration": 0.117658,
     "end_time": "2022-01-27T10:34:08.065487",
     "exception": false,
     "start_time": "2022-01-27T10:34:07.947829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "By calling the **optimize_hyp** function, the best hyperparameters will be searched and returned once the optimization is completed. We will retrieve the optimal hyperparameters in the variable **optimum_params**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dec934b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:34:08.334446Z",
     "iopub.status.busy": "2022-01-27T10:34:08.332772Z",
     "iopub.status.idle": "2022-01-27T10:35:27.272056Z",
     "shell.execute_reply": "2022-01-27T10:35:27.273454Z",
     "shell.execute_reply.started": "2022-01-27T09:42:44.278294Z"
    },
    "papermill": {
     "duration": 79.071742,
     "end_time": "2022-01-27T10:35:27.273724",
     "exception": false,
     "start_time": "2022-01-27T10:34:08.201982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "optimum_params = optimize_hyp(\n",
    "    MODEL_SPECS['class'],\n",
    "    training_set=(X_train, y_train),\n",
    "    search_space=MODEL_SPECS[\"params\"],\n",
    "    metric=lambda x, y: -f1_score(x, y), # Problème de minimisation = inverse du score\n",
    "    evals=MODEL_SPECS[\"max_evals\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b13fe4",
   "metadata": {
    "papermill": {
     "duration": 0.12347,
     "end_time": "2022-01-27T10:35:27.521151",
     "exception": false,
     "start_time": "2022-01-27T10:35:27.397681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's display the optimal hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa620486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:27.767732Z",
     "iopub.status.busy": "2022-01-27T10:35:27.767015Z",
     "iopub.status.idle": "2022-01-27T10:35:27.769565Z",
     "shell.execute_reply": "2022-01-27T10:35:27.770109Z",
     "shell.execute_reply.started": "2022-01-27T09:38:30.356383Z"
    },
    "papermill": {
     "duration": 0.128293,
     "end_time": "2022-01-27T10:35:27.770285",
     "exception": false,
     "start_time": "2022-01-27T10:35:27.641992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimum_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ee6e9f",
   "metadata": {
    "papermill": {
     "duration": 0.123509,
     "end_time": "2022-01-27T10:35:28.016528",
     "exception": false,
     "start_time": "2022-01-27T10:35:27.893019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we know them, we can train a LightGBM with these hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272590ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:28.267275Z",
     "iopub.status.busy": "2022-01-27T10:35:28.266520Z",
     "iopub.status.idle": "2022-01-27T10:35:28.989963Z",
     "shell.execute_reply": "2022-01-27T10:35:28.990708Z",
     "shell.execute_reply.started": "2022-01-27T09:38:30.365234Z"
    },
    "papermill": {
     "duration": 0.8479,
     "end_time": "2022-01-27T10:35:28.990919",
     "exception": false,
     "start_time": "2022-01-27T10:35:28.143019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Each parameter whose schema is overloaded is cast to the correct type\n",
    "for param in MODEL_SPECS['override_schemas']:\n",
    "    cast_instance = MODEL_SPECS['override_schemas'][param]\n",
    "    optimum_params[param] = cast_instance(optimum_params[param])\n",
    "\n",
    "model = LGBMClassifier(**optimum_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "print(\"F1 Score : {:2.1f}%\".format(f1_score(y_test, model.predict(X_test)) * 100))\n",
    "print(\"Precision : {:2.1f}%\".format(precision_score(y_test, model.predict(X_test)) * 100))\n",
    "print(\"Recall : {:2.1f}%\".format(recall_score(y_test, model.predict(X_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4513e0",
   "metadata": {
    "papermill": {
     "duration": 0.123204,
     "end_time": "2022-01-27T10:35:29.240816",
     "exception": false,
     "start_time": "2022-01-27T10:35:29.117612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "What is interesting here is that by trying to maximise the F1 score, we got a better recall, but the precision is lower.\n",
    "\n",
    "<blockquote style='padding:20px'>It would be best not to use only recall to optimise the model: we would get a model with potentially poor precision.</blockquote>\n",
    "\n",
    "In the end, compared to the non-optimized model, we have gained very little in terms of F1 Score, but we have better recall, which was the initial objective since it is mainly this metric that we need to maximize.\n",
    "\n",
    "We will save the model in pkl format, which we will reuse to evaluate and interpret it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacbe820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:29.493762Z",
     "iopub.status.busy": "2022-01-27T10:35:29.492507Z",
     "iopub.status.idle": "2022-01-27T10:35:29.536623Z",
     "shell.execute_reply": "2022-01-27T10:35:29.537213Z",
     "shell.execute_reply.started": "2022-01-27T09:38:31.845480Z"
    },
    "papermill": {
     "duration": 0.173219,
     "end_time": "2022-01-27T10:35:29.537417",
     "exception": false,
     "start_time": "2022-01-27T10:35:29.364198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0307eb2b",
   "metadata": {
    "papermill": {
     "duration": 0.120998,
     "end_time": "2022-01-27T10:35:29.778965",
     "exception": false,
     "start_time": "2022-01-27T10:35:29.657967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#calibration-curve\"></a>    \n",
    "## Calibration curve\n",
    "\n",
    "Calibration curves allow to compare the proportions of positively predicted observations and observations belonging to the positive class from the threshold defining the classifier frontier.\n",
    "defining the frontier of the classifier.\n",
    "\n",
    "Binary classification models does not return 1 or 0, but returns a probability between 0 and 1 (alpha).\n",
    "\n",
    "Let's look at the calibration curve of our optimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c06a6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:30.032523Z",
     "iopub.status.busy": "2022-01-27T10:35:30.031378Z",
     "iopub.status.idle": "2022-01-27T10:35:30.419148Z",
     "shell.execute_reply": "2022-01-27T10:35:30.418615Z",
     "shell.execute_reply.started": "2022-01-27T09:38:31.909767Z"
    },
    "papermill": {
     "duration": 0.518061,
     "end_time": "2022-01-27T10:35:30.419296",
     "exception": false,
     "start_time": "2022-01-27T10:35:29.901235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "prob_pos = model.predict_proba(X_test)[:, 1]\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_test, prob_pos, n_bins=20)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfectly calibrated\", alpha=0.6)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Model\")\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "plt.xlabel(\"Predicted probabilites\")\n",
    "plt.legend()\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.title(\"Calibration curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017c8a8",
   "metadata": {
    "papermill": {
     "duration": 0.1224,
     "end_time": "2022-01-27T10:35:30.664412",
     "exception": false,
     "start_time": "2022-01-27T10:35:30.542012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "What we see is that from 40% onwards, the model contains the right proportions of both positive and negative observations: there is therefore no over-representation of a certain class when the predicted probabilities are above 40%.\n",
    "\n",
    "Below this value, we observe some disparities, but which remain nevertheless controlled over the whole range of probabilities. In view of this curve, we can conclude that the proportions of positive classes are globally respected according to the predicted probabilities.\n",
    "\n",
    "<a id=\"#conclusion-3\"></a>    \n",
    "## Conclusion\n",
    "\n",
    "Hyperparameter optimization may take some effort at first, but once implemented, it is a real force for automation.\n",
    "\n",
    "- We have seen the Bayesian approach to optimising the hyperparameters of a machine learning model.\n",
    "- We optimised a LightGBM with a Tree of Parzen Estimators approach.\n",
    "- The optimized model was saved in Pickle format for later re-use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd77811",
   "metadata": {
    "papermill": {
     "duration": 0.122983,
     "end_time": "2022-01-27T10:35:30.910100",
     "exception": false,
     "start_time": "2022-01-27T10:35:30.787117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#validation-and-interpretability\"></a>\n",
    "# 4. Validation and interpretability\n",
    "\n",
    "To ensure that once in production, the model behaves in a similar way to that encountered in the experimental phase, we need to use tools that allow us to audit it. Although the scores give an idea of the overall performance, they are not sufficient.\n",
    "\n",
    "What we will do:\n",
    "- Evaluate the performance of the model\n",
    "- Interpret the model locally\n",
    "\n",
    "<a id=\"#validate-the-model\"></a>\n",
    "## Validate the model\n",
    "\n",
    "The first objectives of validation are to ensure that the calibrated model respects certain constraints that are not solely related to performance or score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3a7ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:31.162357Z",
     "iopub.status.busy": "2022-01-27T10:35:31.161647Z",
     "iopub.status.idle": "2022-01-27T10:35:31.225082Z",
     "shell.execute_reply": "2022-01-27T10:35:31.225745Z",
     "shell.execute_reply.started": "2022-01-27T09:38:32.306977Z"
    },
    "papermill": {
     "duration": 0.191728,
     "end_time": "2022-01-27T10:35:31.225978",
     "exception": false,
     "start_time": "2022-01-27T10:35:31.034250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1117a67c",
   "metadata": {
    "papermill": {
     "duration": 0.124419,
     "end_time": "2022-01-27T10:35:31.476024",
     "exception": false,
     "start_time": "2022-01-27T10:35:31.351605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#class-densities\"></a>\n",
    "## Class densities\n",
    "\n",
    "We have seen that the precision of our model was less good than the recall. In particular, with the calibration curve, we could observe that on predicted probabilities (positive class) lower than 40%, the proportions of really positive observations did not adopt a linear behaviour.\n",
    "\n",
    "To better visualise this phenomenon, it is common to represent the densities of the two classes on a graph. Two histograms are displayed, corresponding to the positively and negatively predicted observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84de543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:31.731597Z",
     "iopub.status.busy": "2022-01-27T10:35:31.728917Z",
     "iopub.status.idle": "2022-01-27T10:35:32.182600Z",
     "shell.execute_reply": "2022-01-27T10:35:32.183434Z",
     "shell.execute_reply.started": "2022-01-27T09:38:32.363637Z"
    },
    "papermill": {
     "duration": 0.585364,
     "end_time": "2022-01-27T10:35:32.183818",
     "exception": false,
     "start_time": "2022-01-27T10:35:31.598454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "sns.histplot(y_prob[y_test == 0, 1], alpha=0.5)\n",
    "plt.axvline(np.median(y_prob[y_test == 0, 1]), 0,1, linestyle=\"--\", label=\"Median Class 0\")\n",
    "plt.axvline(np.mean(y_prob[y_test == 0, 1]), 0,1, linestyle=\"-\", label=\"Mean Class 0\")\n",
    "\n",
    "sns.histplot(y_prob[y_test == 1, 1], color=\"darkorange\", alpha=0.4)\n",
    "plt.axvline(np.median(y_prob[y_test == 1, 1]), 0, 1, linestyle=\"--\", color=\"darkorange\", label=\"Median Class 1\")\n",
    "plt.axvline(np.mean(y_prob[y_test == 1, 1]), 0, 1, linestyle=\"-\", color=\"darkorange\", label=\"Mean Class 1\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Predicted probabilites\")\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.title(\"Density Chart\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4badcd5e",
   "metadata": {
    "papermill": {
     "duration": 0.127103,
     "end_time": "2022-01-27T10:35:32.437172",
     "exception": false,
     "start_time": "2022-01-27T10:35:32.310069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As a reminder, we had already calculated the calibration curve of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7bc364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:32.711923Z",
     "iopub.status.busy": "2022-01-27T10:35:32.699829Z",
     "iopub.status.idle": "2022-01-27T10:35:33.005018Z",
     "shell.execute_reply": "2022-01-27T10:35:33.005570Z",
     "shell.execute_reply.started": "2022-01-27T09:38:32.842315Z"
    },
    "papermill": {
     "duration": 0.439199,
     "end_time": "2022-01-27T10:35:33.005756",
     "exception": false,
     "start_time": "2022-01-27T10:35:32.566557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "prob_pos = model.predict_proba(X_test)[:, 1]\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_test, prob_pos, n_bins=20)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfectly calibrated\", alpha=0.6)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Model\")\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "plt.xlabel(\"Predicted probabilites\")\n",
    "plt.legend()\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.title(\"Calibration curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5a36cb",
   "metadata": {
    "papermill": {
     "duration": 0.135007,
     "end_time": "2022-01-27T10:35:33.272513",
     "exception": false,
     "start_time": "2022-01-27T10:35:33.137506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Although the calibration curve is not shocking, we observe on the class densities that both distributions are asymmetric with a mean to the left of the median, reflecting a leftward spread. Although this is expected for the positive class, it is less expected for the negative class. Indeed, the latter should, for a perfect model, be spread to the right, so the majority of observations are on the left.\n",
    "\n",
    "In itself, this graph does not block the validation of the model, it simply translates in a visual way that the model has more difficulties to predict with a high confidence low probabilities.\n",
    "\n",
    "<a id=\"#roc-curve\"></a>\n",
    "## ROC curve\n",
    "\n",
    "The ROC curve plots the sensitivity of the model against its specificity. In other words, __it plots the true positive rate__ against the false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a718b",
   "metadata": {
    "papermill": {
     "duration": 0.142903,
     "end_time": "2022-01-27T10:35:33.589341",
     "exception": false,
     "start_time": "2022-01-27T10:35:33.446438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5134cd87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:33.881377Z",
     "iopub.status.busy": "2022-01-27T10:35:33.880601Z",
     "iopub.status.idle": "2022-01-27T10:35:34.316703Z",
     "shell.execute_reply": "2022-01-27T10:35:34.316157Z",
     "shell.execute_reply.started": "2022-01-27T09:38:33.153630Z"
    },
    "papermill": {
     "duration": 0.580068,
     "end_time": "2022-01-27T10:35:34.316857",
     "exception": false,
     "start_time": "2022-01-27T10:35:33.736789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:2.1f}%)'.format(auc(fpr, tpr) * 100))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.title(\"ROC Curve\", fontsize=16)\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de99d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:34.583205Z",
     "iopub.status.busy": "2022-01-27T10:35:34.582461Z",
     "iopub.status.idle": "2022-01-27T10:35:34.645614Z",
     "shell.execute_reply": "2022-01-27T10:35:34.646313Z",
     "shell.execute_reply.started": "2022-01-27T09:38:33.490415Z"
    },
    "papermill": {
     "duration": 0.195971,
     "end_time": "2022-01-27T10:35:34.646528",
     "exception": false,
     "start_time": "2022-01-27T10:35:34.450557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the AUC\n",
    "print(\"The AUC: {}%\".format(round(roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f9b62",
   "metadata": {
    "papermill": {
     "duration": 0.129249,
     "end_time": "2022-01-27T10:35:34.907299",
     "exception": false,
     "start_time": "2022-01-27T10:35:34.778050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#precision-recall-curve\"></a>    \n",
    "## Precision-recall curve\n",
    "\n",
    "Another curve also used is the PR curve, which will plot the evolution of precision as a function of recall.\n",
    "\n",
    "The curve is even, which means that the predictions are made evenly on all data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00b6ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:35.181872Z",
     "iopub.status.busy": "2022-01-27T10:35:35.181162Z",
     "iopub.status.idle": "2022-01-27T10:35:35.510099Z",
     "shell.execute_reply": "2022-01-27T10:35:35.510606Z",
     "shell.execute_reply.started": "2022-01-27T09:38:33.560228Z"
    },
    "papermill": {
     "duration": 0.469645,
     "end_time": "2022-01-27T10:35:35.510781",
     "exception": false,
     "start_time": "2022-01-27T10:35:35.041136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict_proba(X_test)\n",
    "\n",
    "plt.figure(figsize=(16,11))\n",
    "prec, recall, _ = precision_recall_curve(y_test, model.predict_proba(X_test)[:,1], pos_label=1)\n",
    "pr_display = PrecisionRecallDisplay(precision=prec, recall=recall).plot(ax=plt.gca())\n",
    "plt.title(\"PR Curve\", fontsize=16)\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c7f9b8",
   "metadata": {
    "papermill": {
     "duration": 0.131238,
     "end_time": "2022-01-27T10:35:35.778406",
     "exception": false,
     "start_time": "2022-01-27T10:35:35.647168",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The main difference between ROC and PR curves is that precision and recall calculate rates from true positives without regard to true negatives. Precision does not intervene.\\\n",
    "Unlike the ROC curve, precision does not use the TPR, but the PPV! \\\n",
    "In contrast, the ROC curve uses all the information.\n",
    "\n",
    "If we are not interested in specificity, then the PR curve can be interesting to interpret. If not, the ROC curve may provide more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66d102",
   "metadata": {
    "papermill": {
     "duration": 0.133307,
     "end_time": "2022-01-27T10:35:36.043383",
     "exception": false,
     "start_time": "2022-01-27T10:35:35.910076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#shapley-values\"></a> \n",
    "## Shapley values\n",
    "\n",
    "Shapley values provide a method of local interpretability: they allow us to answer the question \"why does this user have a high probability of buying?\n",
    "\n",
    "Shapley values have their origins in cooperative game theory. These values were calculated by Lloyd Shapley in 1953. Shapley values indicate the fair distribution of gains among the players (or actors) in a coalition in a cooperative game. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceafd3f",
   "metadata": {
    "papermill": {
     "duration": 0.147675,
     "end_time": "2022-01-27T10:35:36.336270",
     "exception": false,
     "start_time": "2022-01-27T10:35:36.188595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"#SHAP\"></a>\n",
    "## SHAP\n",
    "\n",
    "In 2017, Scott Lundberg proposed SHAP as a unified measure of variable importance. His idea is as follows:\n",
    "\n",
    "- We consider the variables to be the players.\n",
    "- The total coalition represents the set of variables, and the payoff is the prediction of the model\n",
    "\n",
    "Ideally, a Shapley value for a variable would tell us what its contribution to the prediction is. For example, a Shapley value close to 0 would mean that the variable did not have much impact on the prediction, while a high value would indicate that the variable has a strong impact on the price of housing.\n",
    "\n",
    "With SHAP, we will be able to calculate these Shapley values (approximately or exactly for decision trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f7c7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:36.609648Z",
     "iopub.status.busy": "2022-01-27T10:35:36.608907Z",
     "iopub.status.idle": "2022-01-27T10:35:42.132220Z",
     "shell.execute_reply": "2022-01-27T10:35:42.132902Z",
     "shell.execute_reply.started": "2022-01-27T09:38:33.887727Z"
    },
    "papermill": {
     "duration": 5.660479,
     "end_time": "2022-01-27T10:35:42.133142",
     "exception": false,
     "start_time": "2022-01-27T10:35:36.472663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Explainer object\n",
    "explainer = shap.TreeExplainer(model)\n",
    "X_shap = X_test.copy()\n",
    "\n",
    "# We recover the Shapley values in the matrix (for the positive proba)\n",
    "shap_values = explainer.shap_values(X_shap)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13de302f",
   "metadata": {
    "papermill": {
     "duration": 0.134847,
     "end_time": "2022-01-27T10:35:42.404009",
     "exception": false,
     "start_time": "2022-01-27T10:35:42.269162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To make it easier to interpret the Shapley values of an observation, we will break down each variable on a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f9351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:42.680537Z",
     "iopub.status.busy": "2022-01-27T10:35:42.679748Z",
     "iopub.status.idle": "2022-01-27T10:35:43.069761Z",
     "shell.execute_reply": "2022-01-27T10:35:43.069177Z",
     "shell.execute_reply.started": "2022-01-27T09:38:45.155872Z"
    },
    "papermill": {
     "duration": 0.530531,
     "end_time": "2022-01-27T10:35:43.069904",
     "exception": false,
     "start_time": "2022-01-27T10:35:42.539373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function displays the Shapley values as a bar chart\n",
    "def plot_shapley_values(index):\n",
    "    shap_df = pd.DataFrame.from_dict({\n",
    "        'Variabel': X_shap.columns + \" (\" + X_shap.iloc[0, :].values.astype(str) + \")\",\n",
    "        'Shapley value': shap_values[index, :]\n",
    "    })\n",
    "\n",
    "    # As a reminder, the prediction is equal to the sum of the Shapley values + the mean value\n",
    "    prob = explainer.expected_value[1] + shap_df['Shapley value'].sum()\n",
    "    prob = 1 / (1 + np.exp(-prob))\n",
    "\n",
    "    plt.figure(figsize=(13,10))\n",
    "    sns.barplot(\n",
    "        y='Variabel',\n",
    "        x='Shapley value',\n",
    "        data=shap_df.sort_values('Shapley value', ascending=False)\n",
    "    )\n",
    "    plt.title(\n",
    "        \"Probability: {:2.2f}%\".format(prob * 100),\n",
    "        fontsize=18\n",
    "    )\n",
    "    plt.yticks(fontsize=13)\n",
    "    \n",
    "plot_shapley_values(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032171e5",
   "metadata": {
    "papermill": {
     "duration": 0.132445,
     "end_time": "2022-01-27T10:35:43.341493",
     "exception": false,
     "start_time": "2022-01-27T10:35:43.209048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Concerning the selected user, the model is undecided as it predicts almost 50/50. What we notice is that this particular product (product_id) contributes strongly to lowering the probability.\n",
    "\n",
    "Let's look at another user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8112397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:43.613770Z",
     "iopub.status.busy": "2022-01-27T10:35:43.613089Z",
     "iopub.status.idle": "2022-01-27T10:35:43.989300Z",
     "shell.execute_reply": "2022-01-27T10:35:43.989857Z",
     "shell.execute_reply.started": "2022-01-27T09:38:45.535114Z"
    },
    "papermill": {
     "duration": 0.514349,
     "end_time": "2022-01-27T10:35:43.990056",
     "exception": false,
     "start_time": "2022-01-27T10:35:43.475707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_shapley_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92950248",
   "metadata": {
    "papermill": {
     "duration": 0.135975,
     "end_time": "2022-01-27T10:35:44.269314",
     "exception": false,
     "start_time": "2022-01-27T10:35:44.133339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For this user, however, there is a very high probability of purchase. The most impactful variables are the number of views and number of sessions.\n",
    "\n",
    "In some cases, it is possible to make a global interpretation by displaying the Shapley values of each variable and each observation.\n",
    "\n",
    "The colour change indicates whether the variable has a high value or not. \\\n",
    "Red = high association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552b0265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:44.544060Z",
     "iopub.status.busy": "2022-01-27T10:35:44.543288Z",
     "iopub.status.idle": "2022-01-27T10:35:45.865336Z",
     "shell.execute_reply": "2022-01-27T10:35:45.865847Z",
     "shell.execute_reply.started": "2022-01-27T09:38:45.897635Z"
    },
    "papermill": {
     "duration": 1.461961,
     "end_time": "2022-01-27T10:35:45.866055",
     "exception": false,
     "start_time": "2022-01-27T10:35:44.404094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_shap, plot_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dda5fe7",
   "metadata": {
    "papermill": {
     "duration": 0.139774,
     "end_time": "2022-01-27T10:35:46.146882",
     "exception": false,
     "start_time": "2022-01-27T10:35:46.007108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "While there is an increasing trend for **num_views_session** or **duration**, this is more difficult for product_id, brand or category, which is to be expected as we had done a dictionary encoding: there is therefore no order relationship between the variables.\n",
    "\n",
    "Let's look in detail at the Shapley values for the **product_id** variable only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e493c2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:46.427382Z",
     "iopub.status.busy": "2022-01-27T10:35:46.426725Z",
     "iopub.status.idle": "2022-01-27T10:35:46.583315Z",
     "shell.execute_reply": "2022-01-27T10:35:46.584033Z",
     "shell.execute_reply.started": "2022-01-27T09:38:47.262862Z"
    },
    "papermill": {
     "duration": 0.297438,
     "end_time": "2022-01-27T10:35:46.584239",
     "exception": false,
     "start_time": "2022-01-27T10:35:46.286801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"product_id\", shap_values, X_shap, interaction_index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426eafb8",
   "metadata": {
    "papermill": {
     "duration": 0.13934,
     "end_time": "2022-01-27T10:35:46.870011",
     "exception": false,
     "start_time": "2022-01-27T10:35:46.730671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is interesting to see that certain tiers are formed: specifically between 2e7 and 3e7, there are certain products that positively influence the probability of buying, as their values rise to 4.\n",
    "\n",
    "<blockquote style='padding:20px'>The Shapley value does not represent a probability! It is the calculation before going through the logistic function.</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4bc597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:47.160744Z",
     "iopub.status.busy": "2022-01-27T10:35:47.159689Z",
     "iopub.status.idle": "2022-01-27T10:35:47.381420Z",
     "shell.execute_reply": "2022-01-27T10:35:47.380759Z",
     "shell.execute_reply.started": "2022-01-27T09:38:47.439513Z"
    },
    "papermill": {
     "duration": 0.369258,
     "end_time": "2022-01-27T10:35:47.381588",
     "exception": false,
     "start_time": "2022-01-27T10:35:47.012330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"hour\", shap_values, X_shap, interaction_index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa610934",
   "metadata": {
    "papermill": {
     "duration": 0.144702,
     "end_time": "2022-01-27T10:35:47.671107",
     "exception": false,
     "start_time": "2022-01-27T10:35:47.526405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For the time of visit, we also observe a decreasing average behaviour between 5am and 5pm, then an increase until midnight. This decrease can be explained by the fact that from 5pm onwards, there are many more connections than in the middle of the night, and that these users are more often undecided than those visiting the site at night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7591885e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T10:35:47.955555Z",
     "iopub.status.busy": "2022-01-27T10:35:47.954768Z",
     "iopub.status.idle": "2022-01-27T10:35:48.186315Z",
     "shell.execute_reply": "2022-01-27T10:35:48.185671Z",
     "shell.execute_reply.started": "2022-01-27T09:38:47.644232Z"
    },
    "papermill": {
     "duration": 0.375661,
     "end_time": "2022-01-27T10:35:48.186472",
     "exception": false,
     "start_time": "2022-01-27T10:35:47.810811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"num_views_session\", shap_values, X_shap, interaction_index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e97158c",
   "metadata": {
    "papermill": {
     "duration": 0.142188,
     "end_time": "2022-01-27T10:35:48.473729",
     "exception": false,
     "start_time": "2022-01-27T10:35:48.331541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Contrary to what we might think, Shapley values are high for low values of num_views_sessions. From 5 visits in the same session onwards, Shapley values are more diffuse but average around 0.5, thus lowering the probability slightly.\n",
    "\n",
    "<blockquote style='padding:20px'>Always keep in mind that there are interactions between variables, and that having high Shapley values for low values cannot be summed up in this one variable.</blockquote>\n",
    "\n",
    "<a id=\"#conclusion\"></a>\n",
    "# Conclusion\n",
    "\n",
    "This validation step is important, since when we automate the training of the model, only these graphs and interpretations will allow us to verify that the model is really performing, and not only in terms of metrics.\n",
    "\n",
    "- We have validated the model with the help of graphs.\n",
    "- We interpreted locally some observations with Shapley values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 198.594276,
   "end_time": "2022-01-27T10:35:49.728902",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-27T10:32:31.134626",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
